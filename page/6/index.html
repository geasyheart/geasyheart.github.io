<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta name="baidu-site-verification" content="code-Wz3hIIlkFx" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="https://geasyheart.github.io">
  <title>博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="张宇个人博客">
<meta property="og:type" content="website">
<meta property="og:title" content="博客">
<meta property="og:url" content="https://geasyheart.github.io/page/6/index.html">
<meta property="og:site_name" content="博客">
<meta property="og:description" content="张宇个人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="张宇">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159619272-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?43b413fe1001abcf8dacd99ddd72347d";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/assets/avatar.jpeg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/tags/%E7%AE%97%E6%B3%95">算法</a></li>
	        
				<li><a href="/tags/%E5%B0%8F%E6%A1%A5%E6%B5%81%E6%B0%B4%E4%BA%BA%E5%AE%B6/">小桥流水人家</a></li>
	        
				<li><a href="/tags/python/">python</a></li>
	        
				<li><a href="/tags/linux/">linux</a></li>
	        
				<li><a href="/tags/MySQL/">mysql</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/geasyheart" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
		        
					<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:geasyheart@163.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/assets/avatar.jpeg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
				
			
				
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/geasyheart" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
			        
						<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:geasyheart@163.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 70%">
				
				
					<li style="width: 16.666666666666668%"><a href="/">主页</a></li>
		        
					<li style="width: 16.666666666666668%"><a href="/tags/%E7%AE%97%E6%B3%95">算法</a></li>
		        
					<li style="width: 16.666666666666668%"><a href="/tags/%E5%B0%8F%E6%A1%A5%E6%B5%81%E6%B0%B4%E4%BA%BA%E5%AE%B6/">小桥流水人家</a></li>
		        
					<li style="width: 16.666666666666668%"><a href="/tags/python/">python</a></li>
		        
					<li style="width: 16.666666666666668%"><a href="/tags/linux/">linux</a></li>
		        
					<li style="width: 16.666666666666668%"><a href="/tags/MySQL/">mysql</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-transformer使用示例" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/12/22/transformer%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/">transformer使用示例</a>
    </h1>
  

        
        <a href="/2021/12/22/transformer%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/" class="archive-article-date">
  	<time datetime="2021-12-22T02:25:25.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-12-22</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>关于transformer的一些基础知识，之前在看李宏毅视频的时候总结了一些，可以看<a target="_blank" rel="noopener" href="https://github.com/geasyheart/algo/tree/m2/python/learn_transformer">here</a>，到写此文章时，也基本忘的差不多了，故也不深究，讲两个关于transformer的基本应用，来方便理解与应用。</p>
<h2 id="序列标注"><a href="#序列标注" class="headerlink" title="序列标注"></a>序列标注</h2><p>参考文件<a target="_blank" rel="noopener" href="https://github.com/HIT-SCIR/plm-nlp-code/blob/main/chp4/transformer_postag.py">transformer_postag.py</a>.</p>
<h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1. 加载数据"></a>1. 加载数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加载数据</span></span><br><span class="line">train_data, test_data, vocab, pos_vocab = load_treebank()</span><br></pre></td></tr></table></figure>

<p>其中load_treebank代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_treebank</span>():</span><br><span class="line">    <span class="comment"># 需要翻墙下载，可以自行设置代码</span></span><br><span class="line">    nltk.set_proxy(<span class="string">&#x27;http://192.168.0.28:1080&#x27;</span>)</span><br><span class="line">    <span class="comment"># 如果没有的话那么则会下载，否则忽略</span></span><br><span class="line">    nltk.download(<span class="string">&#x27;treebank&#x27;</span>)</span><br><span class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> treebank</span><br><span class="line"></span><br><span class="line">    sents, postags = <span class="built_in">zip</span>(*(<span class="built_in">zip</span>(*sent) <span class="keyword">for</span> sent <span class="keyword">in</span> treebank.tagged_sents()))</span><br><span class="line"></span><br><span class="line">    vocab = Vocab.build(sents, reserved_tokens=[<span class="string">&quot;&lt;pad&gt;&quot;</span>])</span><br><span class="line"></span><br><span class="line">    tag_vocab = Vocab.build(postags)</span><br><span class="line"></span><br><span class="line">    train_data = [(vocab.convert_tokens_to_ids(sentence), tag_vocab.convert_tokens_to_ids(tags)) <span class="keyword">for</span> sentence, tags <span class="keyword">in</span> <span class="built_in">zip</span>(sents[:<span class="number">3000</span>], postags[:<span class="number">3000</span>])]</span><br><span class="line">    test_data = [(vocab.convert_tokens_to_ids(sentence), tag_vocab.convert_tokens_to_ids(tags)) <span class="keyword">for</span> sentence, tags <span class="keyword">in</span> <span class="built_in">zip</span>(sents[<span class="number">3000</span>:], postags[<span class="number">3000</span>:])]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_data, test_data, vocab, tag_vocab</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>加载后可以看到，<code>train_data</code>和<code>test_data</code>都是list，其中每一个sample都是tuple,分别是input和target。如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>train_data[<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Out[<span class="number">1</span>]: </span><br><span class="line">([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>],</span><br><span class="line"> [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">11</span>])</span><br></pre></td></tr></table></figure>

<h3 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2. 数据处理"></a>2. 数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 这个函数就是将其变成等长，填充使用&lt;pad&gt;，至于是0还是1还是其他值并不重要，因为还有mask~</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">examples</span>):</span><br><span class="line">    lengths = torch.tensor([<span class="built_in">len</span>(ex[<span class="number">0</span>]) <span class="keyword">for</span> ex <span class="keyword">in</span> examples])</span><br><span class="line">    inputs = [torch.tensor(ex[<span class="number">0</span>]) <span class="keyword">for</span> ex <span class="keyword">in</span> examples]</span><br><span class="line">    targets = [torch.tensor(ex[<span class="number">1</span>]) <span class="keyword">for</span> ex <span class="keyword">in</span> examples]</span><br><span class="line">    inputs = pad_sequence(inputs, batch_first=<span class="literal">True</span>, padding_value=vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>])</span><br><span class="line">    targets = pad_sequence(targets, batch_first=<span class="literal">True</span>, padding_value=vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>])</span><br><span class="line">    <span class="keyword">return</span> inputs, lengths, targets, inputs != vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3-模型部分"><a href="#3-模型部分" class="headerlink" title="3. 模型部分"></a>3. 模型部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, dropout=<span class="number">0.1</span>, max_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line"></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + self.pe[:x.size(<span class="number">0</span>), :]</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embedding_dim, hidden_dim, num_class,</span></span><br><span class="line"><span class="params">                 dim_feedforward=<span class="number">512</span>, num_head=<span class="number">2</span>, num_layers=<span class="number">2</span>, dropout=<span class="number">0.1</span>, max_len=<span class="number">512</span>, activation: <span class="built_in">str</span> = <span class="string">&quot;relu&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Transformer, self).__init__()</span><br><span class="line">        <span class="comment"># 词嵌入层</span></span><br><span class="line">        self.embedding_dim = embedding_dim</span><br><span class="line">        self.embeddings = nn.Embedding(vocab_size, embedding_dim)</span><br><span class="line">        self.position_embedding = PositionalEncoding(embedding_dim, dropout, max_len)</span><br><span class="line">        <span class="comment"># 编码层：使用Transformer</span></span><br><span class="line">        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_head, dim_feedforward, dropout, activation)</span><br><span class="line">        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)</span><br><span class="line">        <span class="comment"># 输出层</span></span><br><span class="line">        self.output = nn.Linear(hidden_dim, num_class)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, lengths</span>):</span><br><span class="line">        inputs = torch.transpose(inputs, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        hidden_states = self.embeddings(inputs)</span><br><span class="line">        hidden_states = self.position_embedding(hidden_states)</span><br><span class="line">        attention_mask = length_to_mask(lengths) == <span class="literal">False</span></span><br><span class="line">        hidden_states = self.transformer(hidden_states, src_key_padding_mask=attention_mask).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        logits = self.output(hidden_states)</span><br><span class="line">        log_probs = F.log_softmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> log_probs</span><br></pre></td></tr></table></figure>

<p>这里有几点可能需要注意的：</p>
<ul>
<li>PositionalEncoding</li>
</ul>
<p>因为self attention是没有像rnn位置信息编码的，所以transformer引入了positional encoding，使用绝对位置进行编码，对每一个输入加上position信息，可以看<code>self.pe</code>，这个一个static lookup table。目前也出现一些使用relative positional encoding的，也就是加入相对位置编码，这个在ner任务中挺常见，比如<a target="_blank" rel="noopener" href="https://github.com/fastnlp/TENER">TENER</a>和<a target="_blank" rel="noopener" href="https://github.com/LeeSureman/Flat-Lattice-Transformer">Flat-Lattice-Transformer</a>。但是最近google证明这种相对位置编码只是引入了更多的信息特征进来😭😭😭😭。。</p>
<p>扯完上面这个，进入正题，那就是如何计算的。</p>
<p>看forward部分，发现首先进行了torch.transpose操作，然后进行self.position_embedding，这个transpose是否让你感到困惑呢？<br>如果没有就不用看了😭😭😭。。。</p>
<p>一般输入Embedding的shape是(batch_size, seq_length)，然后对每个seq_length那维的token进行编码获取对应的feature。但是这里将其transpose了，变成了(seq_length, batch_size)，这种操作是否理解呢？ok，举个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
<p>这个就是我们通常理解的(batch_size, seq_length)，如果将其transpose下就变成了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>囔，是不是理解了呢，是对position进行embedding，然后接着看PositionalEncoding是如何forward的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    x = x + self.pe[:x.size(<span class="number">0</span>), :]</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape</span><br><span class="line">Out[<span class="number">2</span>]: torch.Size([<span class="number">70</span>, <span class="number">32</span>, <span class="number">128</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>self.pe.shape</span><br><span class="line">Out[<span class="number">3</span>]: torch.Size([<span class="number">512</span>, <span class="number">1</span>, <span class="number">128</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>那么上述例子就是指获取<code>self.pe</code>前70个长度的位置编码信息，然后和<code>x</code>进行相加返回，从而带入了位置编码信息。</p>
<ul>
<li>TransformerEncoder部分</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>encoder_layer = nn.TransformerEncoderLayer(d_model=<span class="number">512</span>, nhead=<span class="number">8</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>src = torch.rand(<span class="number">10</span>, <span class="number">32</span>, <span class="number">512</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>out = encoder_layer(src)</span><br></pre></td></tr></table></figure>

<p>这部分就容易理解了，使用多少nhead和TransformerEncoder的num_layers。</p>
<h2 id="句子极性二分类"><a href="#句子极性二分类" class="headerlink" title="句子极性二分类"></a>句子极性二分类</h2><p>这地方基本和之前一样，就是linear n_out&#x3D;2，然后交叉熵算loss就行。<br>我稍微改动了下源码，这样理解起来会更方便。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, embedding_dim, hidden_dim, num_class,</span></span><br><span class="line"><span class="params">                 dim_feedforward=<span class="number">512</span>, num_head=<span class="number">2</span>, num_layers=<span class="number">2</span>, dropout=<span class="number">0.1</span>, max_len=<span class="number">128</span>, activation: <span class="built_in">str</span> = <span class="string">&quot;relu&quot;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Transformer, self).__init__()</span><br><span class="line">        <span class="comment"># 词嵌入层</span></span><br><span class="line">        self.embedding_dim = embedding_dim</span><br><span class="line">        self.embeddings = nn.Embedding(vocab_size, embedding_dim)</span><br><span class="line">        self.position_embedding = PositionalEncoding(embedding_dim, dropout, max_len)</span><br><span class="line">        <span class="comment"># 编码层：使用Transformer</span></span><br><span class="line">        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_head, dim_feedforward, dropout, activation)</span><br><span class="line">        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)</span><br><span class="line">        <span class="comment"># 输出层</span></span><br><span class="line">        self.output = nn.Linear(hidden_dim, num_class)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, lengths</span>):</span><br><span class="line">        inputs = torch.transpose(inputs, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        hidden_states = self.embeddings(inputs)</span><br><span class="line">        hidden_states = self.position_embedding(hidden_states)</span><br><span class="line">        lengths = lengths.cpu()</span><br><span class="line">        attention_mask = length_to_mask(lengths) == <span class="literal">False</span></span><br><span class="line">        attention_mask = attention_mask.cuda()</span><br><span class="line">        hidden_states = self.transformer(hidden_states, src_key_padding_mask=attention_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在这里，因为把seq_length那一维放前面，觉得有点怪怪的，所以这里transpose一下。</span></span><br><span class="line">        hidden_states = hidden_states.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        hidden_states = hidden_states[:, <span class="number">0</span>, :]</span><br><span class="line">        output = self.output(hidden_states)</span><br><span class="line">        log_probs = F.log_softmax(output, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> log_probs</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>目前nlp都变成了微调时代，关于transformer网络结构，感兴趣可以点击我上面链接，可以看看从代码层面如果实现encoder和decoder部分。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/12/22/transformer%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-coreference-resolution" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/12/17/coreference-resolution/">coreference resolution</a>
    </h1>
  

        
        <a href="/2021/12/17/coreference-resolution/" class="archive-article-date">
  	<time datetime="2021-12-17T06:32:21.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-12-17</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>共指解析，按照百度的定义如下：</p>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">众所周知，人们为了避免重复，习惯用代词、称谓和缩略语来指代前面提到的实体全称。例如，在文章开始处会写“哈尔滨工业大学”，后面可能会说“哈工大”、“工大”等，还会提到“这所大学”、“她”等。这种现象称为共指现象。</span><br></pre></td></tr></table></figure>
<p>简而言之，其目的在于自动识别表示同一实体的名词短语或代词等。</p>
<p>举个例子：</p>
<blockquote>
<p>哈尔滨工业大学，一般学生或者大众喜欢简称为哈工大，工大等，她是一所美丽的大学。</p>
</blockquote>
<p>实体(entity): 应是唯一定义的，并且具有共知的。<code>哈尔滨工业大学</code>即为这句话的实体。<br>指称(mention): 实体在自然语言文本中的另外一种表达形式，<code>哈工大</code>，<code>工大</code>，<code>她</code>都是指称。<br>共指(coreference): 如果文本或句子中的两个或多个mention指向同一个entity，那么则称为共指。</p>
<p>到这里可以看出，一个复杂的句子中可能会有多个实体以及对应的多个指称共指于不同的实体，这可以是一个分类任务也可以是一个聚类任务。</p>
<p>根据认知，中文里面能做实体的一般是<code>专有名词</code>，比如<code>清华大学</code>，<code>《海蒂》</code>，各行各业有不同的专有名词。另外就是<code>名词</code>或者<code>名词短语</code>以及<code>代词</code>，比如<code>这人</code>，<code>他</code>，<code>它</code>，<code>她</code>等。</p>
<p>下面介绍一种算法。</p>
<h2 id="Word-Level-Coreference-Resolution"><a href="#Word-Level-Coreference-Resolution" class="headerlink" title="Word-Level Coreference Resolution"></a>Word-Level Coreference Resolution</h2><p>论文地址: <a target="_blank" rel="noopener" href="https://aclanthology.org/2021.emnlp-main.605/">Word-Level Coreference Resolution</a><br>代码地址：<a target="_blank" rel="noopener" href="https://github.com/vdobrovolskii/wl-coref">wl-coref</a></p>
<p>先说个人感受，这个咋感觉更像是提升速度，topK操作，而没有那么多骚操作来提升效果。代码质量杠杠的，但是不是batch训练，又有点怪怪的～</p>
<p>代码对于训练部分看完了，如果有说的不对的，或者没有涵盖到重点的，非常欢迎指教！</p>
<h3 id="1-获得word-level-embedding"><a href="#1-获得word-level-embedding" class="headerlink" title="1. 获得word level embedding"></a>1. 获得word level embedding</h3><ul>
<li>获取subtoken输入bert后得到的向量</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_bertify</span>(<span class="params">self, doc: Doc</span>) -&gt; torch.Tensor:</span><br><span class="line">    subwords_batches = bert.get_subwords_batches(doc, self.config,</span><br><span class="line">                                                    self.tokenizer)</span><br><span class="line"></span><br><span class="line">    special_tokens = np.array([self.tokenizer.cls_token_id,</span><br><span class="line">                                self.tokenizer.sep_token_id,</span><br><span class="line">                                self.tokenizer.pad_token_id])</span><br><span class="line">    subword_mask = ~(np.isin(subwords_batches, special_tokens))</span><br><span class="line"></span><br><span class="line">    subwords_batches_tensor = torch.tensor(subwords_batches,</span><br><span class="line">                                            device=self.config.device,</span><br><span class="line">                                            dtype=torch.long)</span><br><span class="line">    subword_mask_tensor = torch.tensor(subword_mask,</span><br><span class="line">                                        device=self.config.device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Obtain bert output for selected batches only</span></span><br><span class="line">    attention_mask = (subwords_batches != self.tokenizer.pad_token_id)</span><br><span class="line">    out, _ = self.bert(</span><br><span class="line">        subwords_batches_tensor,</span><br><span class="line">        attention_mask=torch.tensor(</span><br><span class="line">            attention_mask, device=self.config.device))</span><br><span class="line">    <span class="keyword">del</span> _</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [n_subwords, bert_emb]</span></span><br><span class="line">    <span class="keyword">return</span> out[subword_mask_tensor]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>获取word level embedding</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Tuple</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> coref.config <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> coref.const <span class="keyword">import</span> Doc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WordEncoder</span>(torch.nn.Module):  <span class="comment"># pylint: disable=too-many-instance-attributes</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features: <span class="built_in">int</span>, config: Config</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.attn = torch.nn.Linear(in_features=features, out_features=<span class="number">1</span>)</span><br><span class="line">        self.dropout = torch.nn.Dropout(config.dropout_rate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,  <span class="comment"># type: ignore  # pylint: disable=arguments-differ  #35566 in pytorch</span></span></span><br><span class="line"><span class="params">                doc: Doc,</span></span><br><span class="line"><span class="params">                x: torch.Tensor,</span></span><br><span class="line"><span class="params">                </span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, ...]:</span><br><span class="line"></span><br><span class="line">        word_boundaries = torch.tensor(doc[<span class="string">&quot;word2subword&quot;</span>], device=self.device)</span><br><span class="line">        <span class="comment"># 每个token被tokenizer为subtokens后，starts记录每个token的起始位置</span></span><br><span class="line">        starts = word_boundaries[:, <span class="number">0</span>]</span><br><span class="line">        <span class="comment"># ends记录每个token的结束位置</span></span><br><span class="line">        ends = word_boundaries[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [n_mentions, features]</span></span><br><span class="line">        words = self._attn_scores(x, starts, ends).mm(x)</span><br><span class="line"></span><br><span class="line">        words = self.dropout(words)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (words, self._cluster_ids(doc))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_attn_scores</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                     bert_out: torch.Tensor,</span></span><br><span class="line"><span class="params">                     word_starts: torch.Tensor,</span></span><br><span class="line"><span class="params">                     word_ends: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line"></span><br><span class="line">        n_subtokens = <span class="built_in">len</span>(bert_out)</span><br><span class="line">        n_words = <span class="built_in">len</span>(word_starts)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [n_mentions, n_subtokens]</span></span><br><span class="line">        <span class="comment"># with 0 at positions belonging to the words and -inf elsewhere</span></span><br><span class="line">        <span class="comment"># 只有start到end之间的为0,否则为-inf</span></span><br><span class="line">        attn_mask = torch.arange(<span class="number">0</span>, n_subtokens, device=self.device).expand((n_words, n_subtokens))</span><br><span class="line">        attn_mask = ((attn_mask &gt;= word_starts.unsqueeze(<span class="number">1</span>))</span><br><span class="line">                     * (attn_mask &lt; word_ends.unsqueeze(<span class="number">1</span>)))</span><br><span class="line">        attn_mask = torch.log(attn_mask.to(torch.<span class="built_in">float</span>))</span><br><span class="line">        <span class="comment"># 每一个subtoken被降维为1,比如一个句子有477个subtokens，bert_out为(477, 768)，attn_scores就变成了(1,477)</span></span><br><span class="line">        attn_scores = self.attn(bert_out).T  <span class="comment"># [1, n_subtokens]</span></span><br><span class="line">        attn_scores = attn_scores.expand((n_words, n_subtokens))</span><br><span class="line">        attn_scores = attn_mask + attn_scores</span><br><span class="line">        <span class="keyword">del</span> attn_mask</span><br><span class="line">        <span class="comment"># 做归一化</span></span><br><span class="line">        <span class="keyword">return</span> torch.softmax(attn_scores, dim=<span class="number">1</span>)  <span class="comment"># [n_words, n_subtokens]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>这部分可以看我最后<a href="#word-level%E5%AE%9E%E7%8E%B0demo">简单示例</a>，说明实现方式。</li>
</ul>
<p>假设tokens长度为455, 这里输出就变成了word level embedding。</p>
<h2 id="粗排-rough-score"><a href="#粗排-rough-score" class="headerlink" title="粗排(rough score)"></a>粗排(rough score)</h2><p>还是觉得，不考虑batch_size那一维，整个代码都方便理解许多😂😂😂😂😂😂😂😂😂😂。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RoughScorer</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features: <span class="built_in">int</span>, config: Config</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dropout = torch.nn.Dropout(config.dropout_rate)</span><br><span class="line">        self.bilinear = torch.nn.Linear(features, features)</span><br><span class="line"></span><br><span class="line">        self.k = config.rough_k</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,  <span class="comment"># type: ignore  # pylint: disable=arguments-differ  #35566 in pytorch</span></span></span><br><span class="line"><span class="params">                mentions: torch.Tensor,</span></span><br><span class="line"><span class="params">                </span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, torch.Tensor]:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里一共做了两件事情</span></span><br><span class="line">        <span class="comment"># 1. 获取token和token之间的关联矩阵，可用于表示之间的关联程度。</span></span><br><span class="line">        <span class="comment"># [n_mentions, n_mentions]</span></span><br><span class="line">        pair_mask = torch.arange(mentions.shape[<span class="number">0</span>])</span><br><span class="line">        pair_mask = pair_mask.unsqueeze(<span class="number">1</span>) - pair_mask.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        pair_mask = torch.log((pair_mask &gt; <span class="number">0</span>).to(torch.<span class="built_in">float</span>))</span><br><span class="line">        pair_mask = pair_mask.to(mentions.device) <span class="comment"># -- 首先构建掩码矩阵，该矩阵为一个下三角矩阵，含义为每个词只能取该词之前的词作为候选词。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 但是有啥说啥，我就搞不明白为啥这里还要加一个bilinear，这不有点多此一举么，维度没发生改变，谁能知道给我解答下～</span></span><br><span class="line">        <span class="comment"># 不过没人看😂😂😂😂😂😂</span></span><br><span class="line">        bilinear_scores = self.dropout(self.bilinear(mentions)).mm(mentions.T)</span><br><span class="line"></span><br><span class="line">        rough_scores = pair_mask + bilinear_scores</span><br><span class="line">        <span class="comment"># 2. 获取每个token的topK tokens。</span></span><br><span class="line">        <span class="keyword">return</span> self._prune(rough_scores)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_prune</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">               rough_scores: torch.Tensor</span></span><br><span class="line"><span class="params">               </span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, torch.Tensor]:</span><br><span class="line">        <span class="comment"># 骚气吧，是不是又get到新操作。不过这个sorted，不管true还是false结果都不变😂😂😂😂😂😂</span></span><br><span class="line">        top_scores, indices = torch.topk(rough_scores,</span><br><span class="line">                                         k=<span class="built_in">min</span>(self.k, <span class="built_in">len</span>(rough_scores)),</span><br><span class="line">                                         dim=<span class="number">1</span>, <span class="built_in">sorted</span>=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> top_scores, indices</span><br></pre></td></tr></table></figure>

<h2 id="获取词对特征"><a href="#获取词对特征" class="headerlink" title="获取词对特征"></a>获取词对特征</h2><p>看到么看到么，人家到这里才开始干活～</p>
<p>top_indices的维度为(405,50)，表示这个句子一共有405个tokens，然后获取每个token最相关联的50个tokens的索引。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,  <span class="comment"># type: ignore  # pylint: disable=arguments-differ  #35566 in pytorch</span></span></span><br><span class="line"><span class="params">            top_indices: torch.Tensor,</span></span><br><span class="line"><span class="params">            doc: Doc</span>) -&gt; torch.Tensor:</span><br><span class="line">    word_ids = torch.arange(<span class="number">0</span>, <span class="built_in">len</span>(doc[<span class="string">&quot;cased_words&quot;</span>]), device=self.device)</span><br><span class="line">    <span class="comment"># 一、same speaker特征</span></span><br><span class="line">    speaker_map = torch.tensor(self._speaker_map(doc), device=self.device)</span><br><span class="line">    <span class="comment"># 获取speaker_map对应位置的值，最终输出维度和top_indices一样</span></span><br><span class="line">    <span class="comment"># 看这一步操作，妥妥让我难理解半个小时～</span></span><br><span class="line">    <span class="comment"># 1. speaker_map[top_indices]这里，第一次见这种map操作，学习了</span></span><br><span class="line">    <span class="comment"># 2. 这种广播写法让我觉得，emmmmm，还不如expand下来的更直接</span></span><br><span class="line">    same_speaker = (speaker_map[top_indices] == speaker_map.unsqueeze(<span class="number">1</span>))  <span class="comment"># 广播</span></span><br><span class="line">    same_speaker = self.speaker_emb(same_speaker.to(torch.long))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 二、距离特征</span></span><br><span class="line">    <span class="comment"># 这个特征我觉得还是挺有用的，1、加速了训练和推理速度 2、加快收敛速度</span></span><br><span class="line">    <span class="comment"># bucketing the distance (see __init__())</span></span><br><span class="line">    distance = (word_ids.unsqueeze(<span class="number">1</span>) - word_ids[top_indices]</span><br><span class="line">                ).clamp_min_(<span class="built_in">min</span>=<span class="number">1</span>) <span class="comment"># 小于1的变成1</span></span><br><span class="line">    log_distance = distance.to(torch.<span class="built_in">float</span>).log2().floor_()</span><br><span class="line">    log_distance = log_distance.clamp_max_(<span class="built_in">max</span>=<span class="number">6</span>).to(torch.long) <span class="comment"># 大于最大值的元素将变为最大值。 那么就是64</span></span><br><span class="line">    <span class="comment"># 一会log_distance一会distance的，看着就不容易理解，直接到log_distance多好😂😂😂😂😂😂</span></span><br><span class="line">    distance = torch.where(distance &lt; <span class="number">5</span>, distance - <span class="number">1</span>, log_distance + <span class="number">2</span>)</span><br><span class="line">    distance = self.distance_emb(distance)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 三、同一文档特征</span></span><br><span class="line">    genre = torch.tensor(self.genre2int[doc[<span class="string">&quot;document_id&quot;</span>][:<span class="number">2</span>]],</span><br><span class="line">                            device=self.device).expand_as(top_indices)</span><br><span class="line">    genre = self.genre_emb(genre)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> self.dropout(torch.cat((same_speaker, distance, genre), dim=<span class="number">2</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="AnaphoricityScorer"><a href="#AnaphoricityScorer" class="headerlink" title="AnaphoricityScorer"></a>AnaphoricityScorer</h3><p>这部分看着有点绕，看如下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, *,  <span class="comment"># type: ignore  # pylint: disable=arguments-differ  #35566 in pytorch</span></span></span><br><span class="line"><span class="params">            all_mentions: torch.Tensor,</span></span><br><span class="line"><span class="params">            mentions_batch: torch.Tensor,</span></span><br><span class="line"><span class="params">            pw_batch: torch.Tensor,</span></span><br><span class="line"><span class="params">            top_indices_batch: torch.Tensor,</span></span><br><span class="line"><span class="params">            top_rough_scores_batch: torch.Tensor,</span></span><br><span class="line"><span class="params">            </span>) -&gt; torch.Tensor:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [batch_size, n_ants, pair_emb]</span></span><br><span class="line">    pair_matrix = self._get_pair_matrix(</span><br><span class="line">        all_mentions, mentions_batch, pw_batch, top_indices_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [batch_size, n_ants]</span></span><br><span class="line">    scores = top_rough_scores_batch + self._ffnn(pair_matrix)</span><br><span class="line">    scores = utils.add_dummy(scores, eps=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_ffnn</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculates anaphoricity scores.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: tensor of shape [batch_size, n_ants, n_features]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        tensor of shape [batch_size, n_ants]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = self.out(self.hidden(x))</span><br><span class="line">    <span class="keyword">return</span> x.squeeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_get_pair_matrix</span>(<span class="params">all_mentions: torch.Tensor,</span></span><br><span class="line"><span class="params">                     mentions_batch: torch.Tensor,</span></span><br><span class="line"><span class="params">                     pw_batch: torch.Tensor,</span></span><br><span class="line"><span class="params">                     top_indices_batch: torch.Tensor,</span></span><br><span class="line"><span class="params">                     </span>) -&gt; torch.Tensor:</span><br><span class="line">    </span><br><span class="line">    emb_size = mentions_batch.shape[<span class="number">1</span>]</span><br><span class="line">    n_ants = pw_batch.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 计算所有tokens和这50个tokens的关联度</span></span><br><span class="line">    a_mentions = mentions_batch.unsqueeze(<span class="number">1</span>).expand(-<span class="number">1</span>, n_ants, emb_size)</span><br><span class="line">    b_mentions = all_mentions[top_indices_batch]</span><br><span class="line">    similarity = a_mentions * b_mentions</span><br><span class="line"></span><br><span class="line">    out = torch.cat((a_mentions, b_mentions, similarity, pw_batch), dim=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<p>_get_pair_matrix中的b_mentions，可参考<a href="#%E5%8F%96%E7%B4%A2%E5%BC%95%E6%93%8D%E4%BD%9C">b_mentions</a>。后续接了个ffnn，获得其最终得分。</p>
<p>整体代码作者挺喜欢参差网络和前馈神经网络这种操作。</p>
<h3 id="loss计算"><a href="#loss计算" class="headerlink" title="loss计算"></a>loss计算</h3><p>CorefLoss计算分成了两部分，一个是NLML，另外一个BCELoss.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_nlml</span>(<span class="params">input_: torch.Tensor, target: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="comment"># gold这地方明显就想计算相关性。</span></span><br><span class="line">    gold = torch.logsumexp(input_ + torch.log(target), dim=<span class="number">1</span>)</span><br><span class="line">    input_ = torch.logsumexp(input_, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> (input_ - gold).mean()</span><br></pre></td></tr></table></figure>

<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="word-level实现demo"><a href="#word-level实现demo" class="headerlink" title="word-level实现demo"></a>word-level实现demo</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf8 -*-</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WordEmbedding</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_in, p</span>):</span><br><span class="line">        <span class="built_in">super</span>(WordEmbedding, self).__init__()</span><br><span class="line">        self.n_in = n_in</span><br><span class="line">        self.p = p</span><br><span class="line">        self.linear = torch.nn.Linear(in_features=n_in, out_features=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, indices</span>):</span><br><span class="line">        start_end_indices_to_tensor = torch.tensor(indices)</span><br><span class="line">        start_indices = start_end_indices_to_tensor[:, <span class="number">0</span>]</span><br><span class="line">        end_indices = start_end_indices_to_tensor[:, <span class="number">1</span>]</span><br><span class="line">        mask = torch.arange(<span class="number">5</span>).expand(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">        attn_mask = (mask &gt;= start_indices.unsqueeze(<span class="number">1</span>)) * (mask &lt; end_indices.unsqueeze(<span class="number">1</span>))</span><br><span class="line">        attn_mask = torch.log(attn_mask.to(torch.<span class="built_in">float</span>))</span><br><span class="line">        attn_scores = self.linear(x).T</span><br><span class="line">        attn_scores = attn_scores.expand((<span class="built_in">len</span>(indices), x.size(<span class="number">0</span>)))</span><br><span class="line">        attn_scores = attn_scores + attn_mask</span><br><span class="line">        <span class="keyword">return</span> torch.softmax(attn_scores, dim=<span class="number">1</span>).mm(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 假设为：我 是 中国人,5为每个subtoken，10为每个subtoken的embedding</span></span><br><span class="line">    word_feature = torch.arange(<span class="number">50</span>, dtype=torch.<span class="built_in">float</span>).view(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 那么index是：</span></span><br><span class="line">    start_end_indices = [(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line">    we = WordEmbedding(n_in=<span class="number">10</span>, p=<span class="number">0.1</span>)</span><br><span class="line">    we.forward(word_feature, start_end_indices)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="取索引操作"><a href="#取索引操作" class="headerlink" title="取索引操作"></a>取索引操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>],</span><br><span class="line">        [ <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">        [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># b对应top50选出来的index</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[b]</span><br><span class="line">tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>],</span><br><span class="line">         [ <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>]],</span><br><span class="line"></span><br><span class="line">        [[ <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">         [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>],</span><br><span class="line">         [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>]]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[b].shape</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="精彩例子"><a href="#精彩例子" class="headerlink" title="精彩例子"></a>精彩例子</h3><p>这种写法我挺喜欢的，比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>aa</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mm</span><br><span class="line">tensor([[ <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">        [<span class="literal">False</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一般会在最后计算loss时加上mask进行降维铺平</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>aa[mm]</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 形式1： 作者将无关的score置为-inf</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>aa * torch.log(mm.to(torch.<span class="built_in">float</span>))</span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, -inf, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [-inf, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 形式2：</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>aa * mm</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>



      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/12/17/coreference-resolution/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-活到老学到老之index操作" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/12/16/%E6%B4%BB%E5%88%B0%E8%80%81%E5%AD%A6%E5%88%B0%E8%80%81%E4%B9%8Bindex%E6%93%8D%E4%BD%9C/">活到老学到老之index操作</a>
    </h1>
  

        
        <a href="/2021/12/16/%E6%B4%BB%E5%88%B0%E8%80%81%E5%AD%A6%E5%88%B0%E8%80%81%E4%B9%8Bindex%E6%93%8D%E4%BD%9C/" class="archive-article-date">
  	<time datetime="2021-12-16T02:20:21.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-12-16</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>快速想一想，你能想到torch有哪些常见的index操作？？</p>
<h2 id="1-gather"><a href="#1-gather" class="headerlink" title="1. gather"></a>1. gather</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.gather(dim=<span class="number">1</span>, index=torch.tensor([[<span class="number">0</span>,<span class="number">1</span>], [<span class="number">1</span>,<span class="number">2</span>]]))</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-index-select"><a href="#2-index-select" class="headerlink" title="2. index_select"></a>2. index_select</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.index_select(dim=<span class="number">1</span>, index=torch.tensor([<span class="number">1</span>,<span class="number">2</span>]))</span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3-骚气的来了哦"><a href="#3-骚气的来了哦" class="headerlink" title="3. 骚气的来了哦"></a>3. 骚气的来了哦</h2><p>根据上面例子可以看到，<code>a</code>为矩阵，选择<code>a</code>中的index，但是下面介绍一个map操作.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>index</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor([<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>, <span class="number">66</span>, <span class="number">77</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>, <span class="number">66</span>, <span class="number">77</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[index]</span><br><span class="line">tensor([[<span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>],</span><br><span class="line">        [<span class="number">55</span>, <span class="number">66</span>, <span class="number">77</span>]])</span><br></pre></td></tr></table></figure>

<p>这种操作有一个真实场景，比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 这是两个特征</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words = [<span class="string">&#x27;我&#x27;</span>, <span class="string">&#x27;爱&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;国&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pos = [<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;n&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 假设words变成了一个4 * 4的临接矩阵，用于表示每个token和其他token的一个关联重要程度</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words_attn = torch.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words_attn</span><br><span class="line">tensor([[<span class="number">0.6279</span>, <span class="number">0.6234</span>, <span class="number">0.9831</span>, <span class="number">0.5267</span>],</span><br><span class="line">        [<span class="number">0.2265</span>, <span class="number">0.8453</span>, <span class="number">0.5740</span>, <span class="number">0.4772</span>],</span><br><span class="line">        [<span class="number">0.7759</span>, <span class="number">0.6952</span>, <span class="number">0.1758</span>, <span class="number">0.3800</span>],</span><br><span class="line">        [<span class="number">0.9998</span>, <span class="number">0.3138</span>, <span class="number">0.5078</span>, <span class="number">0.5565</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scores, indices = words_attn.topk(k=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>indices</span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 假设pos转为了</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pos_tensor = torch.tensor([<span class="number">111</span>, <span class="number">222</span>, <span class="number">333</span>, <span class="number">444</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. map操作</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pos_tensor[indices]</span><br><span class="line">tensor([[<span class="number">333</span>, <span class="number">111</span>],</span><br><span class="line">        [<span class="number">222</span>, <span class="number">333</span>],</span><br><span class="line">        [<span class="number">111</span>, <span class="number">222</span>],</span><br><span class="line">        [<span class="number">111</span>, <span class="number">444</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 随后就可以接一个embedding搞事情了</span></span><br><span class="line">pos_embedding(pos_tensor[indices])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 总结，这个示例的优点可以看出是快速计算，取topK然后再结合其他的特征进行操作。</span></span><br></pre></td></tr></table></figure>

<h2 id="4-batch-gather"><a href="#4-batch-gather" class="headerlink" title="4. batch_gather"></a>4. batch_gather</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_gather</span>(<span class="params">data: torch.Tensor, index: torch.Tensor</span>):</span><br><span class="line">    index = index.unsqueeze(-<span class="number">1</span>).repeat_interleave(data.size()[-<span class="number">1</span>], dim=-<span class="number">1</span>)  <span class="comment"># (bs, n, hidden)</span></span><br><span class="line">    <span class="comment"># index = index.unsqueeze(-1).expand(*(*index.shape, data.shape[-1]))</span></span><br><span class="line">    <span class="keyword">return</span> torch.gather(data, <span class="number">1</span>, index)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    a = torch.randn(<span class="number">3</span>, <span class="number">128</span>, <span class="number">312</span>)</span><br><span class="line">    indices = torch.tensor([</span><br><span class="line">        [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">7</span>, <span class="number">7</span>]</span><br><span class="line">    ])</span><br><span class="line">    output = batch_gather(a, indices)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    <span class="built_in">print</span>((output[<span class="number">0</span>][<span class="number">0</span>] == a[<span class="number">0</span>][<span class="number">1</span>]).<span class="built_in">all</span>())</span><br><span class="line">    <span class="built_in">print</span>((output[<span class="number">0</span>][<span class="number">1</span>] == a[<span class="number">0</span>][<span class="number">2</span>]).<span class="built_in">all</span>())</span><br><span class="line">    <span class="built_in">print</span>((output[<span class="number">1</span>][<span class="number">0</span>] == a[<span class="number">1</span>][<span class="number">5</span>]).<span class="built_in">all</span>())</span><br><span class="line">    <span class="built_in">print</span>((output[<span class="number">1</span>][<span class="number">1</span>] == a[<span class="number">1</span>][<span class="number">6</span>]).<span class="built_in">all</span>())</span><br><span class="line">    <span class="built_in">print</span>((output[<span class="number">2</span>][<span class="number">0</span>] == a[<span class="number">2</span>][<span class="number">7</span>]).<span class="built_in">all</span>())</span><br><span class="line">    <span class="built_in">print</span>((output[<span class="number">2</span>][<span class="number">1</span>] == a[<span class="number">2</span>][<span class="number">7</span>]).<span class="built_in">all</span>())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/12/16/%E6%B4%BB%E5%88%B0%E8%80%81%E5%AD%A6%E5%88%B0%E8%80%81%E4%B9%8Bindex%E6%93%8D%E4%BD%9C/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-语义依存分析" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/11/15/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/">语义依存分析</a>
    </h1>
  

        
        <a href="/2021/11/15/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/" class="archive-article-date">
  	<time datetime="2021-11-15T15:41:54.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-11-15</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="定义-ltp"><a href="#定义-ltp" class="headerlink" title="定义(ltp)"></a>定义(<a target="_blank" rel="noopener" href="https://www.ltp-cloud.com/intro#sdp_how">ltp</a>)</h2><p>语义依存分析 (Semantic Dependency Parsing, SDP)，分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。<br>使用语义依存刻画句子语义，好处在于不需要去抽象词汇本身，而是通过词汇所承受的语义框架来描述该词汇，而论元的数目相对词汇来说数量总是少了很多的。<br>语义依存分析目标是跨越句子表层句法结构的束缚，直接获取深层的语义信息。<br>例如以下三个句子，用不同的表达方式表达了同一个语义信息，即张三实施了一个吃的动作，吃的动作是对苹果实施的。</p>
<img src="/2021/11/15/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/intro_how_sdp.1.jpg" class="" title="intro_how_sdp.1">
<br>
<img src="/2021/11/15/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/intro_how_sdp.2.jpg" class="" title="intro_how_sdp.2">
<br>
<img src="/2021/11/15/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/intro_how_sdp.3.jpg" class="" title="intro_how_sdp.3">

<p>语义依存分析不受句法结构的影响，将具有直接语义关联的语言单元直接连接依存弧并标记上相应的语义关系。这也是语义依存分析与句法依存分析的重要区别。</p>
<img src="/2021/11/15/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/intro_dp_vs_sdp.jpg" class="" title="intro_dp_vs_sdp">

<p>如上例对比了句法依存和语义分析的结果，可以看到两者存在两个显著差别。<br>第一，句法依存某种程度上更重视非实词（如介词）在句子结构分析中的作用，而语义依存更倾向在具有直接语义关联的实词之间建立直接依存弧，非实词作为辅助标记存在。<br>第二，两者依存弧上标记的语义关系完全不同，语义依存关系是由论元关系引申归纳而来，可以用于回答问题，如我在哪里喝汤，我在用什么喝汤，谁在喝汤，我在喝什么。但是句法依存却没有这个能力。<br>第三，句法依存为树结构，语义依存为图结构，即是说当前词的依存弧可以有多个。</p>
<p>语义依存与语义角色标注之间也存在关联，语义角色标注只关注句子主要谓词的论元及谓词与论元之间的关系，而语义依存不仅关注谓词与论元的关系，还关注谓词与谓词之间、论元与论元之间、论元内部的语义关系。语义依存对句子语义信息的刻画更加完整全面。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><a target="_blank" rel="noopener" href="https://github.com/geasyheart/semantic-dependency-parser">https://github.com/geasyheart/semantic-dependency-parser</a></p>
<p>欢迎Star!</p>
<h3 id="1-数据集"><a href="#1-数据集" class="headerlink" title="1. 数据集"></a>1. 数据集</h3><p>目前貌似公开的只有SEMEVAL2016数据集，地址在：<a target="_blank" rel="noopener" href="https://github.com/HIT-SCIR/SemEval-2016">HIT-SCIR&#x2F;SemEval-2016</a>，代码仓库中的数据集是将text和news两类合并而来。</p>
<blockquote>
<p>额外插一句，对于一个算法项目来讲，不仅仅是算法部分，还要有数据，即使不能公开，也可以造一些例子，能够跑通算法，HanLP在这方面真的是无敌存在！</p>
</blockquote>
<h3 id="2-模型结构"><a href="#2-模型结构" class="headerlink" title="2. 模型结构"></a>2. 模型结构</h3><ul>
<li>这里使用到的模型结构：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">semantic_dependency_parser.py [line:<span class="number">34</span>] INFO SemanticDependencyModel(</span><br><span class="line">  (encoder): TransformerEmbedding(hfl/chinese-electra-180g-small-discriminator, n_layers=<span class="number">4</span>, n_out=<span class="number">256</span>, stride=<span class="number">256</span>, pooling=mean, pad_index=<span class="number">0</span>, dropout=<span class="number">0.33</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">  (tag_embedding): Embedding(<span class="number">41</span>, <span class="number">64</span>)</span><br><span class="line">  (edge_mlp_d): MLP(n_in=<span class="number">320</span>, n_out=<span class="number">600</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">  (edge_mlp_h): MLP(n_in=<span class="number">320</span>, n_out=<span class="number">600</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">  (label_mlp_d): MLP(n_in=<span class="number">320</span>, n_out=<span class="number">600</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">  (label_mlp_h): MLP(n_in=<span class="number">320</span>, n_out=<span class="number">600</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">  (edge_attn): Biaffine(n_in=<span class="number">600</span>, n_out=<span class="number">2</span>, bias_x=<span class="literal">True</span>, bias_y=<span class="literal">True</span>)</span><br><span class="line">  (label_attn): Biaffine(n_in=<span class="number">600</span>, n_out=<span class="number">158</span>, bias_x=<span class="literal">True</span>, bias_y=<span class="literal">True</span>)</span><br><span class="line">  (criterion): CrossEntropyLoss()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>HanLP使用的模型结构:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">BiaffineDependencyModel(</span><br><span class="line">    (encoder): EncoderWithContextualLayer()</span><br><span class="line">    (biaffine_decoder): BiaffineDecoder(</span><br><span class="line">    (mlp_arc_h): MLP(n_in=<span class="number">256</span>, n_out=<span class="number">500</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">    (mlp_arc_d): MLP(n_in=<span class="number">256</span>, n_out=<span class="number">500</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">    (mlp_rel_h): MLP(n_in=<span class="number">256</span>, n_out=<span class="number">100</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">    (mlp_rel_d): MLP(n_in=<span class="number">256</span>, n_out=<span class="number">100</span>, dropout=<span class="number">0.33</span>)</span><br><span class="line">    (arc_attn): Biaffine(n_in=<span class="number">500</span>, n_out=<span class="number">1</span>, bias_x=<span class="literal">True</span>)</span><br><span class="line">    (rel_attn): Biaffine(n_in=<span class="number">100</span>, n_out=<span class="number">136</span>, bias_x=<span class="literal">True</span>, bias_y=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>和dependency parser结构相同，但是loss计算和解码部分不同。</p>
<p>区别点在于，举个例子:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pred_arcs.shape</span></span><br><span class="line">(<span class="number">32</span>, <span class="number">49</span>, <span class="number">49</span>)</span><br><span class="line"><span class="comment"># true_arcs.shape</span></span><br><span class="line">(<span class="number">32</span>, <span class="number">49</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>因为dependency parser有一个限制，即当前词只可能依存其他一个词，那么argmax(-1)即是在49那里获取最大的，表示和这49个词中最大的作为依存关系，使用交叉熵。</p>
<p>而semantic dependency parser没有这个限制，当前词可能和多个词存在依存关系，那么他的pred_arcs和true_arcs的维度是一样的，都是(32, 49, 49)，所以使用BCELoss。</p>
<p>当然也可以用交叉熵，只需要将pred_arcs的维度转换成(32, 49, 49, 2)即可，也是我下面的做法。</p>
<h3 id="3-loss计算和解码"><a href="#3-loss计算和解码" class="headerlink" title="3. loss计算和解码"></a>3. loss计算和解码</h3><p>在<a target="_blank" rel="noopener" href="https://github.com/geasyheart/semantic-dependency-parser/blob/17a2e08f1a8d1d6f022c3e8f9ca959bbf09572f1/src/model.py#L65">这里计算loss</a>时，采用的是交叉熵，也就是说s_edge.size(-1) &#x3D;&#x3D; 2，表示当前词和句子所有词之间<code>是</code>或者<code>否</code>，然后argmax(-1)进行解码。</p>
<p>在<a target="_blank" rel="noopener" href="https://github.com/hankcs/HanLP/blob/b555dbbb5b0b18ee7459bc46508b085bfa10d960/hanlp/components/parsers/biaffine/biaffine_sdp.py#L64">HanLP计算loss</a>时，对于arc(即edge)的shape为(batch_size, seq_length, seq_length)，因为biaffine的输出维度为1,所以这里计算loss时使用BCELoss，表示当前词和句子所有词之间是否存在关系。</p>
<p>另外一个两者的区别点在于计算rel时，HanLP采取的方式是各自计算各自的loss（即arc和rel），然后loss相加。<br>这里计算rel loss时融合了arc的信息进来，好处就在于能够快速收敛和提升准确度吧。</p>
<h2 id="各模块技术指标"><a href="#各模块技术指标" class="headerlink" title="各模块技术指标"></a>各模块技术指标</h2><p><a target="_blank" rel="noopener" href="https://www.ltp-cloud.com/intro#benchmark">https://www.ltp-cloud.com/intro#benchmark</a></p>
<h2 id="ltp关系类型"><a href="#ltp关系类型" class="headerlink" title="ltp关系类型"></a>ltp关系类型</h2>
<table class="table"> <thead><tr> <th>关系类型</th> <th>Tag</th> <th>Description</th> <th>Example</th> </tr></thead> <tbody> <tr> <td>施事关系</td> <td>Agt</td> <td>Agent</td> <td>我送她一束花 (我 &lt;-- 送)</td> </tr> <tr> <td>当事关系</td> <td>Exp</td> <td>Experiencer</td> <td>我跑得快 (跑 --&gt; 我)</td> </tr> <tr> <td>感事关系</td> <td>Aft</td> <td>Affection</td> <td>我思念家乡 (思念 --&gt; 我)</td> </tr> <tr> <td>领事关系</td> <td>Poss</td> <td>Possessor</td> <td>他有一本好读 (他 &lt;-- 有)</td> </tr> <tr> <td>受事关系</td> <td>Pat</td> <td>Patient</td> <td>他打了小明 (打 --&gt; 小明)</td> </tr> <tr> <td>客事关系</td> <td>Cont</td> <td>Content</td> <td>他听到鞭炮声 (听 --&gt; 鞭炮声)</td> </tr> <tr> <td>成事关系</td> <td>Prod</td> <td>Product</td> <td>他写了本小说 (写 --&gt; 小说)</td> </tr> <tr> <td>源事关系</td> <td>Orig</td> <td>Origin</td> <td>我军缴获敌人四辆坦克 (缴获 --&gt; 坦克)</td> </tr> <tr> <td>涉事关系</td> <td>Datv</td> <td>Dative</td> <td>他告诉我个秘密 ( 告诉 --&gt; 我 )</td> </tr> <tr> <td>比较角色</td> <td>Comp</td> <td>Comitative</td> <td>他成绩比我好 (他 --&gt; 我)</td> </tr> <tr> <td>属事角色</td> <td>Belg</td> <td>Belongings</td> <td>老赵有俩女儿 (老赵 &lt;-- 有)</td> </tr> <tr> <td>类事角色</td> <td>Clas</td> <td>Classification</td> <td>他是中学生 (是 --&gt; 中学生)</td> </tr> <tr> <td>依据角色</td> <td>Accd</td> <td>According</td> <td>本庭依法宣判 (依法 &lt;-- 宣判)</td> </tr> <tr> <td>缘故角色</td> <td>Reas</td> <td>Reason</td> <td>他在愁女儿婚事 (愁 --&gt; 婚事)</td> </tr> <tr> <td>意图角色</td> <td>Int</td> <td>Intention</td> <td>为了金牌他拼命努力 (金牌 &lt;-- 努力)</td> </tr> <tr> <td>结局角色</td> <td>Cons</td> <td>Consequence</td> <td>他跑了满头大汗 (跑 --&gt; 满头大汗)</td> </tr> <tr> <td>方式角色</td> <td>Mann</td> <td>Manner</td> <td>球慢慢滚进空门 (慢慢 &lt;-- 滚)</td> </tr> <tr> <td>工具角色</td> <td>Tool</td> <td>Tool</td> <td>她用砂锅熬粥 (砂锅 &lt;-- 熬粥)</td> </tr> <tr> <td>材料角色</td> <td>Malt</td> <td>Material</td> <td>她用小米熬粥 (小米 &lt;-- 熬粥)</td> </tr> <!--<tr> <td>状态角色</td> <td>Stat</td> <td></td> <td></td> </tr> <tr> <td>起始状态</td> <td>Sini</td> <td></td> <td></td> </tr> <tr> <td>终止状态</td> <td>Sfin</td> <td></td> <td></td> </tr> <tr> <td>状态历程</td> <td>Sproc</td> <td></td> <td></td> </tr>--> <tr> <td>时间角色</td> <td>Time</td> <td>Time</td> <td>唐朝有个李白 (唐朝 &lt;-- 有)</td> </tr> <!--<tr> <td>时间起点</td> <td>Tini</td> <td></td> <td></td> </tr> <tr> <td>时间终点</td> <td>Tfni</td> <td></td> <td></td> </tr> <tr> <td>时段角色</td> <td>TDur</td> <td></td> <td></td> </tr> <tr> <td>时距角色</td> <td>Trang</td> <td></td> <td></td> </tr>--> <tr> <td>空间角色</td> <td>Loc</td> <td>Location</td> <td>这房子朝南 (朝 --&gt; 南)</td> </tr> <!--<tr> <td>原处所</td> <td>Lini</td> <td></td> <td></td> </tr> <tr> <td>终处所</td> <td>Lfin</td> <td></td> <td></td> </tr> <tr> <td>通过处所</td> <td>Lthru</td> <td></td> <td></td> </tr>--> <tr> <td>历程角色</td> <td>Proc</td> <td>Process</td> <td>火车正在过长江大桥 (过 --&gt; 大桥)</td> </tr> <tr> <td>趋向角色</td> <td>Dir</td> <td>Direction</td> <td>部队奔向南方 (奔 --&gt; 南)</td> </tr> <tr> <td>范围角色</td> <td>Sco</td> <td>Scope</td> <td>产品应该比质量 (比 --&gt; 质量)</td> </tr> <tr> <td>数量角色</td> <td>Quan</td> <td>Quantity</td> <td>一年有365天 (有 --&gt; 天)</td> </tr> <tr> <td>数量数组</td> <td>Qp</td> <td>Quantity-phrase</td> <td>三本书 (三 --&gt; 本)</td> </tr> <tr> <td>频率角色</td> <td>Freq</td> <td>Frequency</td> <td>他每天看书 (每天 &lt;-- 看)</td> </tr> <tr> <td>顺序角色</td> <td>Seq</td> <td>Sequence</td> <td>他跑第一 (跑 --&gt; 第一)</td> </tr> <!--<tr> <td>变化量角色</td> <td>Nvar</td> <td></td> <td></td> </tr> <tr> <td>起始量</td> <td>Nini</td> <td></td> <td></td> </tr> <tr> <td>终止量</td> <td>Nfin</td> <td></td> <td></td> </tr>--> <tr> <td>描写角色</td> <td>Desc(Feat)</td> <td>Description</td> <td>他长得胖 (长 --&gt; 胖)</td> </tr> <tr> <td>宿主角色</td> <td>Host</td> <td>Host</td> <td>住房面积 (住房 &lt;-- 面积)</td> </tr> <tr> <td>名字修饰角色</td> <td>Nmod</td> <td>Name-modifier</td> <td>果戈里大街 (果戈里 &lt;-- 大街)</td> </tr> <tr> <td>时间修饰角色</td> <td>Tmod</td> <td>Time-modifier</td> <td>星期一上午 (星期一 &lt;-- 上午)</td> </tr>
<tr> <td>反角色</td> <td>r + main role</td> <td></td> <td>打篮球的小姑娘 (打篮球 &lt;-- 姑娘)</td> </tr> <tr> <td>嵌套角色</td> <td>d + main role</td> <td></td> <td>爷爷看见孙子在跑 (看见 --&gt; 跑)</td> </tr> <tr> <td>并列关系</td> <td>eCoo</td> <td>event Coordination</td> <td>我喜欢唱歌和跳舞 (唱歌 --&gt; 跳舞)</td> </tr> <tr> <td>选择关系</td> <td>eSelt</td> <td>event Selection</td> <td>您是喝茶还是喝咖啡 (茶 --&gt; 咖啡)</td> </tr> <tr> <td>等同关系</td> <td>eEqu</td> <td>event Equivalent</td> <td>他们三个人一起走 (他们 --&gt; 三个人)</td> </tr> <tr> <td>先行关系</td> <td>ePrec</td> <td>event Precedent</td> <td>首先，先</td> </tr> <tr> <td>顺承关系</td> <td>eSucc</td> <td>event Successor</td> <td>随后，然后</td> </tr> <tr> <td>递进关系</td> <td>eProg</td> <td>event Progression</td> <td>况且，并且</td> </tr> <tr> <td>转折关系</td> <td>eAdvt</td> <td>event adversative</td> <td>却，然而</td> </tr> <tr> <td>原因关系</td> <td>eCau</td> <td>event Cause</td> <td>因为，既然</td> </tr> <tr> <td>结果关系</td> <td>eResu</td> <td>event Result</td> <td>因此，以致</td> </tr> <tr> <td>推论关系</td> <td>eInf</td> <td>event Inference</td> <td>才，则</td> </tr> <tr> <td>条件关系</td> <td>eCond</td> <td>event Condition</td> <td>只要，除非</td> </tr> <tr> <td>假设关系</td> <td>eSupp</td> <td>event Supposition</td> <td>如果，要是</td> </tr> <tr> <td>让步关系</td> <td>eConc</td> <td>event Concession</td> <td>纵使，哪怕</td> </tr> <tr> <td>手段关系</td> <td>eMetd</td> <td>event Method</td> <td></td> </tr> <tr> <td>目的关系</td> <td>ePurp</td> <td>event Purpose</td> <td>为了，以便</td> </tr> <tr> <td>割舍关系</td> <td>eAban</td> <td>event Abandonment</td> <td>与其，也不</td> </tr> <tr> <td>选取关系</td> <td>ePref</td> <td>event Preference</td> <td>不如，宁愿</td> </tr> <tr> <td>总括关系</td> <td>eSum</td> <td>event Summary</td> <td>总而言之</td> </tr> <tr> <td>分叙关系</td> <td>eRect</td> <td>event Recount</td> <td>例如，比方说</td> </tr> <tr> <td>连词标记</td> <td>mConj</td> <td>Recount Marker</td> <td>和，或</td> </tr> <tr> <td>的字标记</td> <td>mAux</td> <td>Auxiliary </td> <td>的，地，得</td> </tr> <tr> <td>介词标记</td> <td>mPrep</td> <td>Preposition </td> <td>把，被</td> </tr> <tr> <td>语气标记</td> <td>mTone</td> <td>Tone </td> <td>吗，呢</td> </tr> <tr> <td>时间标记</td> <td>mTime</td> <td>Time </td> <td>才，曾经</td> </tr> <tr> <td>范围标记</td> <td>mRang</td> <td>Range </td> <td>都，到处</td> </tr> <tr> <td>程度标记</td> <td>mDegr</td> <td>Degree </td> <td>很，稍微</td> </tr> <tr> <td>频率标记</td> <td>mFreq</td> <td>Frequency Marker </td> <td>再，常常</td> </tr> <tr> <td>趋向标记</td> <td>mDir</td> <td>Direction Marker </td> <td>上去，下来</td> </tr> <tr> <td>插入语标记</td> <td>mPars</td> <td>Parenthesis Marker</td> <td>总的来说，众所周知</td> </tr> <tr> <td>否定标记</td> <td>mNeg</td> <td>Negation Marker</td> <td>不，没，未</td> </tr> <tr> <td>情态标记</td> <td>mMod</td> <td>Modal Marker</td> <td>幸亏，会，能</td> </tr> <tr> <td>标点标记</td> <td>mPunc</td> <td>Punctuation Marker</td> <td>，。！</td> </tr> <tr> <td>重复标记</td> <td>mPept</td> <td>Repetition Marker</td> <td>走啊走 (走 --&gt; 走)</td> </tr> <tr> <td>多数标记</td> <td>mMaj</td> <td>Majority Marker</td> <td>们，等</td> </tr><tr> <td>实词虚化标记</td> <td>mVain</td> <td>Vain Marker </td> <td></td> </tr> <tr> <td>离合标记</td> <td>mSepa</td> <td>Seperation Marker </td> <td>吃了个饭 (吃 --&gt; 饭) 洗了个澡 (洗 --&gt; 澡)</td> </tr> <tr> <td>根节点</td> <td>Root</td> <td>Root </td> <td>全句核心节点</td> </tr> </tbody> </table>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/11/15/%E8%AF%AD%E4%B9%89%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-bio-based语义角色标注" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/11/12/bio-based%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/">bio-based语义角色标注</a>
    </h1>
  

        
        <a href="/2021/11/12/bio-based%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/" class="archive-article-date">
  	<time datetime="2021-11-12T08:22:30.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-11-12</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="定义1："><a href="#定义1：" class="headerlink" title="定义1："></a>定义1：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Semantic Role Labeling (SRL) is defined as the task to recognize arguments for a given predicate and assign semantic role labels to them.</span><br></pre></td></tr></table></figure>

<h3 id="定义2-ltp-："><a href="#定义2-ltp-：" class="headerlink" title="定义2(ltp)："></a>定义2(<a target="_blank" rel="noopener" href="https://www.ltp-cloud.com/intro#srl_how">ltp</a>)：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">语义角色标注 (Semantic Role Labeling, SRL) 是一种浅层的语义分析技术，标注句子中某些短语为给定谓词的论元 (语义角色) ，如施事、受事、时间和地点等。其能够对问答系统、信息抽取和机器翻译等应用产生推动作用。 仍然是上面的例子，语义角色标注的结果为：</span><br></pre></td></tr></table></figure>
<!-- ![](https://www.ltp-cloud.com/static/img/intro_how_srl.jpg) -->
<img src="/2021/11/12/bio-based%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/intro_how_srl.jpg" class="" title="intro_how_srl">

<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><a target="_blank" rel="noopener" href="https://github.com/geasyheart/srl-parser">https://github.com/geasyheart/srl-parser</a></p>
<p>欢迎Star!</p>
<h3 id="示例1："><a href="#示例1：" class="headerlink" title="示例1："></a>示例1：</h3><p><img src="/2021/11/02/%E5%9F%BA%E4%BA%8E%E6%A0%91%E5%BD%A2%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E9%AB%98%E9%98%B6%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/123321.png"><br>看黄色那部分:</p>
<ul>
<li>他叫汤姆，他作为<code>施事者</code>，叫为<code>谓语</code>，汤姆为<code>受事者</code></li>
<li>去拿外衣（为一个完整语义） </li>
<li>汤姆拿外衣，汤姆为<code>施事者</code>，拿为<code>谓语</code>，外衣为<code>受事者</code></li>
</ul>
<h3 id="示例2："><a href="#示例2：" class="headerlink" title="示例2："></a>示例2：</h3><blockquote>
<p>‘各位&#x2F;PN  好&#x2F;VA  ，&#x2F;PU  欢迎&#x2F;VV  您&#x2F;PN  收看&#x2F;VV  国际&#x2F;NN  频道&#x2F;NN  的&#x2F;DEG  今日&#x2F;NT  关注&#x2F;NN  。&#x2F;PU’</p>
</blockquote>
<img src="/2021/11/12/bio-based%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/%E5%90%84%E4%BD%8D%E5%A5%BD%EF%BC%8C%E6%AC%A2%E8%BF%8E%E6%82%A8%E6%94%B6%E7%9C%8B%E5%9B%BD.svg" class="" title="各位好，欢迎您收看国">

<p>此图自己画的，如有需要可<a target="_blank" rel="noopener" href="https://github.com/geasyheart/srl-parser/blob/new_encoder/src/canvas.py">参考</a></p>
<ul>
<li>欢迎您，欢迎为<code>谓语</code>，您为<code>受事者</code>，收看国际频道的今日关注为<code>语义角色</code></li>
<li>其余忽略…</li>
</ul>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集来自<a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/LDC2013T19">ontonotes5.0</a>，但是此为收费数据集，或者需要大学帐号注册，找到一个开源的<a target="_blank" rel="noopener" href="https://github.com/GuocaiL/Coref_Resolution/archive/master.zip#data/">https://github.com/GuocaiL/Coref_Resolution&#x2F;archive&#x2F;master.zip#data&#x2F;</a>，处理后的数据集以 jsonlines后缀存储，放到<a target="_blank" rel="noopener" href="https://github.com/geasyheart/srl-parser/tree/new_encoder/src/data">此处</a>。</p>
<p>具体的处理逻辑可参考<a target="_blank" rel="noopener" href="https://github.com/hankcs/HanLP/blob/b555dbbb5b0b18ee7459bc46508b085bfa10d960/hanlp/datasets/srl/ontonotes5/chinese.py#L60">这里</a>。</p>
<h2 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h2><p>目前常见的有span-based，bio-based，treecrf，treecrf是<a target="_blank" rel="noopener" href="https://github.com/yzhangcs/crfsrl">yzhangcs</a>的实现方式。bio-based是用序列标注的方式来做（hanlp和ltp均以此实现），故是本文的重点。</p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><p>看<a target="_blank" rel="noopener" href="https://github.com/geasyheart/srl-parser/blob/f622f262f01a02df00a9f62d4a94689ac7bed96b/src/transform.py#L65">这个文件</a>，其中预测的label处理后是这个样子，解释如下：</p>
<ul>
<li>各位 好，好是第二个字，和第一个词有关系，关系为3。</li>
<li>欢迎 您收看国际频道的今日关注， 对应关系为1, 13, 23, 23, 23, 23, 23。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">3</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>, <span class="number">13</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">23</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>],</span><br><span class="line">        [ <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>,  <span class="number">0</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>看到这里是否知道其模型结构了，<code>biaffine</code>+<code>crf</code>哇，<code>biaffine</code>转换成临接矩阵，用于预测<code>谓词</code>和<code>论元</code>的关系，<code>论元</code>用crf序列标注的方式来进行预测。</p>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SpanBIOSemanticRoleLabelingModel(</span><br><span class="line">  (transformer): TransformerEncoder(n_out=256,dropout=0.1)</span><br><span class="line">  (s_layer): MLP(n_in=256, n_out=300, dropout=0.1)</span><br><span class="line">  (e_layer): MLP(n_in=256, n_out=300, dropout=0.1)</span><br><span class="line">  (biaffine): Biaffine(n_in=300, n_out=64, bias_x=True, bias_y=True)</span><br><span class="line">  (crf): CRF(num_tags=64)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><h4 id="1-loss计算和解码"><a href="#1-loss计算和解码" class="headerlink" title="1. loss计算和解码"></a>1. loss计算和解码</h4><p>到<code>biaffine</code>这一层没什么需要特别注意的，bert获取词向量的方式从以前的求平均改成了以首字代表词向量。后面接两个mlp以及biaffine。重点在于如何和crf融合到一起？</p>
<ol>
<li>biaffine输出后维度为(batch_size,seq_length,seq_length,hidden_size),crf是用在第二个seq_length那一维。</li>
<li>crf的输入为发射概率，此维度为(batch_size,seq_length,hidden_size)。</li>
</ol>
<p>基于上述两个前提，将<code>batch_size</code>和<code>第一个seq_length</code>进行flatten，因为第一个seq_length为谓语，不影响论元的预测，转换后输入到crf中，就可以计算loss了，解码一样。</p>
<h4 id="2-评估指标"><a href="#2-评估指标" class="headerlink" title="2. 评估指标"></a>2. 评估指标</h4><p>预测出来的结果示例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pred</span></span><br><span class="line"></span><br><span class="line">[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">13</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">23</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"></span><br><span class="line">[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">12</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]</span><br></pre></td></tr></table></figure>

<p>pred类型为<code>List[List[int]]</code>，他的长度等于batch_tokens中每个词的长度，即：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(pred) == <span class="built_in">sum</span>([<span class="built_in">len</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> batch[<span class="string">&quot;batch_tokens&quot;</span>]])</span><br></pre></td></tr></table></figure>

<p>** 其中每一行表示的是当前词和整句每个词所呈现出来的关系。 **</p>
<p>基于上面结论，就不难写评估代码了，将其转成<code>(token_index, start, end, label)</code>，然后set取交集，最终计算f1值，可看<a target="_blank" rel="noopener" href="https://github.com/geasyheart/srl-parser/blob/f622f262f01a02df00a9f62d4a94689ac7bed96b/src/metric.py#L16">这里</a>。</p>
<h4 id="3-解码预测"><a href="#3-解码预测" class="headerlink" title="3. 解码预测"></a>3. 解码预测</h4><p>基本如上，<a target="_blank" rel="noopener" href="https://github.com/geasyheart/srl-parser/blob/f622f262f01a02df00a9f62d4a94689ac7bed96b/src/parser.py#L269">具体可看</a>。</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p><a target="_blank" rel="noopener" href="http://ltp.ai/docs/performance.html#id5">ltp v4</a></p>
<p>从这里也可以看出，语义角色标注任务任重道远。</p>
<h2 id="ltp关系类型"><a href="#ltp关系类型" class="headerlink" title="ltp关系类型"></a>ltp关系类型</h2><p><a target="_blank" rel="noopener" href="http://ltp.ai/docs/appendix.html#id4">ltp关系类型1</a><br><a target="_blank" rel="noopener" href="https://www.ltp-cloud.com/intro#srl_how">ltp关系类型2</a></p>

<table class="docutils align-default"> <colgroup> <col style="width: 8%"> <col style="width: 20%"> <col style="width: 17%"> <col style="width: 55%"> </colgroup> <thead> <tr class="row-odd"><th class="head"><p>关系类型</p></th> <th class="head"><p>Tag</p></th> <th class="head"><p>Description</p></th> <th class="head"><p>Example</p></th> </tr> </thead> <tbody> <tr class="row-even"><td><p>ARG0</p></td> <td><p>causers or experiencers</p></td> <td><p>施事者、主体、触发者</p></td> <td><p>[政府 ARG0]鼓励个人投资服务业。</p></td> </tr> <tr class="row-odd"><td><p>ARG1</p></td> <td><p>patient</p></td> <td><p>受事者</p></td> <td><p>政府鼓励[个人 ARG1]投资服务业。</p></td> </tr> <tr class="row-even"><td><p>ARG2</p></td> <td><p>range</p></td> <td><p>语义角色2</p></td> <td><p>政府鼓励个人[投资服务业 ARG2]。</p></td> </tr> <tr class="row-odd"><td><p>ARG3</p></td> <td><p>starting point</p></td> <td><p>语义角色3</p></td> <td><p>巴基斯坦[对谈判前景 ARG3]表示悲观。</p></td> </tr> <tr class="row-even"><td><p>ARG4</p></td> <td><p>end point</p></td> <td><p>语义角色4</p></td> <td><p>产检部门将产检时间缩短到[一至三天 ARG4]。</p></td> </tr> <tr class="row-odd"><td><p>ADV</p></td> <td><p>adverbial</p></td> <td><p>状语</p></td> <td><p>我们[即将 ADV]迎来新年。</p></td> </tr> <tr class="row-even"><td><p>BNF</p></td> <td><p>beneficiary</p></td> <td><p>受益人</p></td> <td><p>义务[为学童及老师 BNF]做超音波检查 。</p></td> </tr> <tr class="row-odd"><td><p>CND</p></td> <td><p>condition</p></td> <td><p>条件</p></td> <td><p>[如果早期发现 CND],便能提醒当事人注意血压的变化。</p></td> </tr> <tr class="row-even"><td><p>CRD</p></td> <td><p>coordinated arguments</p></td> <td><p>并列</p></td> <td><p>跟南韩、[跟美国 CRD]谋求和平关系的举动也更加积极。</p></td> </tr> <tr class="row-odd"><td><p>DGR</p></td> <td><p>degree</p></td> <td><p>程度</p></td> <td><p>贫铀弹含有放射性比铀强[2０万倍 DGR]。</p></td> </tr> <tr class="row-even"><td><p>DIR</p></td> <td><p>direction</p></td> <td><p>方向</p></td> <td><p>[从此处 DIR] 我们可以发现寇克斯报告的精髓。</p></td> </tr> <tr class="row-odd"><td><p>DIS</p></td> <td><p>discourse marker</p></td> <td><p>会话标记</p></td> <td><p>警方上午针对目击者做笔录，[而 DIS]李士东仍然不见踪影。</p></td> </tr> <tr class="row-even"><td><p>EXT</p></td> <td><p>extent</p></

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/11/12/bio-based%E8%AF%AD%E4%B9%89%E8%A7%92%E8%89%B2%E6%A0%87%E6%B3%A8/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-基于树形条件随机场的高阶句法分析" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/11/02/%E5%9F%BA%E4%BA%8E%E6%A0%91%E5%BD%A2%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E9%AB%98%E9%98%B6%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/">基于树形条件随机场的高阶句法分析</a>
    </h1>
  

        
        <a href="/2021/11/02/%E5%9F%BA%E4%BA%8E%E6%A0%91%E5%BD%A2%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E9%AB%98%E9%98%B6%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/" class="archive-article-date">
  	<time datetime="2021-11-02T06:22:48.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-11-02</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>此篇文章貌似没有重点，日常笔记吧。</p>
<p><a target="_blank" rel="noopener" href="http://hlt.suda.edu.cn/~yzhang/master-thesis/treecrf-ho-syn-parsing.pdf">基于树形条件随机场的高阶句法分析</a>作者硕士毕业论文，关于句法分析的历史与实现基本讲了一遍，包括作者使用TreeCRF高阶建模等工作。<br><a target="_blank" rel="noopener" href="https://github.com/yzhangcs/parser">代码</a>，这个项目包含了句法分析任务的实现。包括dependency parser，semantic dependency parser，constituency parser等。</p>
<p>对于句法分析工作，百度ddparser相比下来可能是工业上更好的选择，不过目前个人更倾向于语义句法工作，相比下来更接近直观感受（还是看任务啦～）。</p>
<p>不管是semantic role labeling(语义角色标注)或者semantic dependency parser(语义依存分析)，看<a target="_blank" rel="noopener" href="http://ltp.ai/demo.html">ltp</a>的演示效果。</p>
<img src="/2021/11/02/%E5%9F%BA%E4%BA%8E%E6%A0%91%E5%BD%A2%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E9%AB%98%E9%98%B6%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/123321.png" class="" title="效果">


<p>但是不能光看这种效果，从目前公开的论文水平来看，准确率并没有很高，另外高质量，高数量的标注数据集也相对少。</p>
<p>大家都是一样的模型，比的就是数据集喽，这点不得不夸HanLP，至少人家代码里面都有数据集，方便学习。</p>
<p><img src="https://catalog.ldc.upenn.edu/desc/addenda/LDC2013T19.cmn.jpg" alt="手动狗头"></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/11/02/%E5%9F%BA%E4%BA%8E%E6%A0%91%E5%BD%A2%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E7%9A%84%E9%AB%98%E9%98%B6%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-属性抽取调研-工业界" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/30/%E5%B1%9E%E6%80%A7%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/">属性抽取调研-工业界</a>
    </h1>
  

        
        <a href="/2021/10/30/%E5%B1%9E%E6%80%A7%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/" class="archive-article-date">
  	<time datetime="2021-10-30T15:12:35.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-10-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="属性抽取调研——工业界"><a href="#属性抽取调研——工业界" class="headerlink" title="属性抽取调研——工业界"></a>属性抽取调研——工业界</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><p><a href="#1-%E4%BB%BB%E5%8A%A1">1. 任务</a></p>
<ul>
<li><a href="#11-%E8%83%8C%E6%99%AF">1.1. 背景</a></li>
<li><a href="#12-%E4%BB%BB%E5%8A%A1%E5%AE%9A%E4%B9%89">1.2. 任务定义</a></li>
<li><a href="#13-%E6%95%B0%E6%8D%AE%E9%9B%86">1.3. 数据集</a></li>
<li><a href="#14-%E8%AF%84%E6%B5%8B%E6%A0%87%E5%87%86">1.4. 评测标准</a></li>
</ul>
</li>
<li><p><a href="#2-%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93">2. 方法总结</a></p>
<ul>
<li><a href="#21-%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E6%A7%BD%E5%A1%AB%E5%85%85%E6%96%B9%E6%B3%95">2.1. 基于无监督的属性抽取方法</a><ul>
<li><a href="#211-%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E6%A7%BD%E5%A1%AB%E5%85%85%E7%AE%97%E6%B3%95">2.1.1. 基于规则的槽填充算法</a></li>
<li><a href="#212%E5%9F%BA%E4%BA%8E%E8%81%9A%E7%B1%BB%E7%9A%84%E5%B1%9E%E6%80%A7%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95">2.1.2.基于聚类的属性抽取方法</a></li>
</ul>
</li>
<li><a href="#22-%E5%9F%BA%E4%BA%8E%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB%E7%9A%84%E5%8D%8A%E7%9B%91%E7%9D%A3%E7%9A%84%E6%A7%BD%E5%A1%AB%E5%85%85%E7%AE%97%E6%B3%95">2.2. 基于依存关系的半监督的槽填充方法</a></li>
<li><a href="#23-%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E6%96%B9%E6%B3%95">2.3. 基于深度学习的序列标注方法</a></li>
<li><a href="#24-%E5%9F%BA%E4%BA%8E%E5%85%83%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%B1%9E%E6%80%A7%E6%8A%BD%E5%8F%96%E6%96%B9%E6%B3%95">2.4.基于元模式的属性抽取方法</a></li>
</ul>
</li>
<li><p><a href="#3-paper-list">3. Paper List</a></p>
<ul>
<li><a href="#31-%E8%AE%BA%E6%96%87%E5%88%97%E8%A1%A8">3.1. 论文列表</a></li>
</ul>
</li>
<li><p><a href="#4-%E7%9B%B8%E5%85%B3%E9%93%BE%E6%8E%A5">4.相关链接</a></p>
</li>
<li><p><a href="#4-%E5%8F%82%E8%80%83%E8%B5%84%E6%BA%90">5.参考资源</a></p>
</li>
</ul>
<h2 id="1-任务"><a href="#1-任务" class="headerlink" title="1. 任务"></a>1. 任务</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1. 背景"></a>1.1. 背景</h3><p>信息抽取是从非结构化、半结构化文本中将有价值的信息转化为结构化数据的过程，在抽取的过程中，根据抽取的内容不同又分为关系抽取、事件抽取、属性抽取等。</p>
<h3 id="1-2-任务定义"><a href="#1-2-任务定义" class="headerlink" title="1.2. 任务定义"></a>1.2. 任务定义</h3><p>属性抽取（Attribute Extraction）：属性抽取的目标是从不同信息源中采集特定实体的属性信息。比如人物实体的生日、性别、国籍等，都是它的属性信息，通过属性抽取，通过多个数据源的获取，我们就可以通过丰富的属性信息来较为完整地刻画一个实体。</p>
<h3 id="1-3-数据集"><a href="#1-3-数据集" class="headerlink" title="1.3. 数据集"></a>1.3. 数据集</h3><ul>
<li>目前属性抽取还没有统一的评测数据集，一般是根据不同的应用场景，对不同的数据进行抽取。</li>
</ul>
<h3 id="1-4-评测标准"><a href="#1-4-评测标准" class="headerlink" title="1.4. 评测标准"></a>1.4. 评测标准</h3><ul>
<li>Accuracy</li>
<li>Precision</li>
<li>f1</li>
</ul>
<h2 id="2-方法总结"><a href="#2-方法总结" class="headerlink" title="2. 方法总结"></a>2. 方法总结</h2><p>可以划分为四类：基于无监督的抽取方法，基于依存关系的半监督的槽填充算法，基于深度学习的序列标注方法、基于元模式的属性抽取方法。</p>
<h3 id="2-1-基于无监督的属性抽取方法"><a href="#2-1-基于无监督的属性抽取方法" class="headerlink" title="2.1. 基于无监督的属性抽取方法"></a>2.1. 基于无监督的属性抽取方法</h3><h4 id="2-1-1-基于规则的槽填充算法"><a href="#2-1-1-基于规则的槽填充算法" class="headerlink" title="2.1.1. 基于规则的槽填充算法"></a>2.1.1. 基于规则的槽填充算法</h4><ul>
<li><p>场景：在纯文本中抽取人物属性</p>
</li>
<li><p>论文：《中文人物属性槽填充技术的研究与实现》</p>
</li>
<li><p>方法：通过人工编写规则针对人物场景进行属性抽取，由于人工构造规则模板比较麻烦，可以使用Bootstrapping方法生成规则。</p>
<p>生成规则的步骤如下：</p>
<p>1、人工置顶规则种子作为初始规则种子集Spatter，属性值集合Sattr</p>
<p>2、使用规则种子集Spatter，遍历并匹配文本中的属性值，获取候选属性集合h</p>
<p>3、计算候选属性值集合h中每个属性值的可行度，将可信度较高的三个属性值加入到种子属性值集合Sattr中，若收敛，则算法结束，否则，执行4</p>
<p>4、使用属性值集合Sattr，遍历文本，由匹配到的属性值的上下文两个词，生成候选模板集合h’</p>
<p>5、计算候选模板集合h’中每个候选模板的可信度，将可信度较高的3个候选模板加入到规则种子集合Spatter中，若Spatter收敛，则算法结束，否则执行步骤2</p>
<p>重复2-5到满足一定的次数。</p>
</li>
<li><p>效果：通过自动生成规则进行抽取的效果不好，准确率较低。</p>
<h4 id="2-1-2-基于聚类的属性抽取方法"><a href="#2-1-2-基于聚类的属性抽取方法" class="headerlink" title="2.1.2. 基于聚类的属性抽取方法"></a>2.1.2. 基于聚类的属性抽取方法</h4></li>
<li><p>场景：产品的属性抽取</p>
</li>
<li><p>论文：《An Unsupervised Approach to Product Attribute Extraction》</p>
</li>
<li><p>方法：</p>
<p>1、数据预处理：</p>
<p>找出限定性的短语和名词短语，论文认为一般属性出现在这种词语中</p>
<p>2、对上一步筛选出的名词进行聚类，删除词语稍少的类</p>
<p>3、从类中抽取属性：计算unigrams, bigrams and trigrams，使用作者定义的属性分数函数进行计算，得分高的则为属性。</p>
</li>
</ul>
<h3 id="2-2-基于依存关系的半监督的槽填充算法"><a href="#2-2-基于依存关系的半监督的槽填充算法" class="headerlink" title="2.2. 基于依存关系的半监督的槽填充算法"></a>2.2. 基于依存关系的半监督的槽填充算法</h3><ul>
<li><p>场景：在纯文本中抽取人物属性</p>
</li>
<li><p>论文：《中文人物属性槽填充技术的研究与实现》</p>
</li>
<li><p>方法：</p>
<p>依存关系：在自然语言处理中，用词与词之间的依存关系来描述语言结构的框架称为依存语法（dependence grammar），又称从属关系语法。利用依存句法进行句法分析也是自然语言理解的重要技术之一。（来自维基百科）。</p>
<p>使用这种方法对人物进行属性抽取的步骤如下:</p>
<p>1、为每个属性生成对应的触发词表</p>
<p>2、根据属性槽特点，识别出句子中所有可能候选属性，比如出生地的NER标注为LOC，感觉是自己设置一些规则匹配一些属性出来</p>
<p>3、通过句子的依存结构，确认侯选属性与主体实体（这里是人物）的关系。将依存关系树看作一个无向图，顶点对应pagerank算法中的网页，利用pagerank算法，计算两个词在句法上的相关性。</p>
<p>4、计算&lt;动词，人名，属性词&gt;三元组的得分，取前top4，看动词是否出现在触发词中。</p>
</li>
<li><p>效果：在有触发词的句子中效果较好，在描述句式灵活且对触发词依赖小的句子中，提取性能不好。</p>
</li>
</ul>
<h3 id="2-3-基于深度学习的序列标注方法"><a href="#2-3-基于深度学习的序列标注方法" class="headerlink" title="2.3. 基于深度学习的序列标注方法"></a>2.3. 基于深度学习的序列标注方法</h3><p>序列标注属于一种较为常用的属性抽取方法，就是将属性值看作较长的实体值，对数据进行标注，使用序列标注模型进行训练和抽取。</p>
<ul>
<li>场景：这种方法被应用于多个场景中，比如人物属性的抽取，抽取在线评论文本的属性、从无上下文信息的标题中抽取产品属性等，只要有相应的标注数据，就可以使用这种方法进行抽取。</li>
<li>论文：《基于弱监督的属性关系抽取方法》《面向非结构化文本的开放式实体属性抽取》《实体 —属性抽取的GRU+CRF方法》《Personal Attributes Extraction in Chinese Text Based on Distant-Supervision and LSTM》《Bootstrapped Named Entity Recognition for Product Attribute Extraction》等论文中都使用了这种方法进行抽取</li>
<li>方法：将属性抽取看作序列标注问题，标注需要花费一定的人工成本，在有些场景下，比如人物属性的抽取，可以使用百度百科等百科词条的结构化信息框进行标注，可以降低一定的人工标注成本；同时，标注时也可以使用Bootstrap方法由种子发现更多潜在属性值，这种方法在《Bootstrapped Named Entity Recognition for Product Attribute Extraction》论文中提到，是一种类似于Pakhomov 2002提出的首字母扩写算法的算法。该算法学习如何将首字母缩写与其正确扩展相关联的上下文，作者认为，分类器在经过标记的已知品牌训练集上进行训练，可以学习可以区分当前含义的上下文模式。序列标注常使用的模型：CRF模型、神经网络模型如BI-GRU+CRF模型等。</li>
<li>效果：使用这种方法进行属性抽取的效果较为理想，但也具有一定的局限性，由于属性值的内容和形式多种多样，对于字数较长的描述性属性，这种方法不能取得理想的效果；同时，对于某些不能使用百科词条数据进行回标的情况，将花费大量的人工成本进行标注，降低了可操作性。</li>
</ul>
<h3 id="2-4-基于元模式的属性抽取方法"><a href="#2-4-基于元模式的属性抽取方法" class="headerlink" title="2.4. 基于元模式的属性抽取方法"></a>2.4. 基于元模式的属性抽取方法</h3><ul>
<li>场景：这种方法可以被应用于多个场景中，不具有局限性</li>
<li>论文：《MetaPAD-Meta Pattern Discovery from Massive Text Corpora》</li>
<li>方法：这种方法可以在海量语料库中发现元模式，在属性抽取的场景中，可以使用这种方法发现高质量的属性描述语句，作为属性值。</li>
</ul>
<h2 id="3-Paper-List"><a href="#3-Paper-List" class="headerlink" title="3. Paper List"></a>3. Paper List</h2><h3 id="3-1-论文列表"><a href="#3-1-论文列表" class="headerlink" title="3.1. 论文列表"></a>3.1. 论文列表</h3><table>
<thead>
<tr>
<th>会议&#x2F;年份</th>
<th>论文</th>
<th>链接</th>
</tr>
</thead>
<tbody><tr>
<td>ACM SIGKDD International Conference 2017</td>
<td>MetaPAD-Meta Pattern Discovery from Massive Text Corpora</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.04213.pdf">https://arxiv.org/pdf/1703.04213.pdf</a></td>
</tr>
</tbody></table>
<p>近几年的属性抽取论文待补充</p>
<h2 id="4-相关链接"><a href="#4-相关链接" class="headerlink" title="4. 相关链接"></a>4. 相关链接</h2><p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D11-1144.pdf">Bootstrapped Named Entity Recognition for Product Attribute Extraction</a></p>
<p><a target="_blank" rel="noopener" href="https://kns-cnki-net-s.vpn.buaa.edu.cn:8118/KXReader/Detail?TIMESTAMP=637359051633928750&DBCODE=CJFD&TABLEName=CJFD2014&FileName=JSJY201401016&RESULT=1&SIGN=Y+J+IYTtv/0DPBF3d5Yl+4Wwvf4=">基于弱监督的属性关系抽取方法</a></p>
<p><a target="_blank" rel="noopener" href="http://gb.oversea.cnki.net/KCMS/detail/detail.aspx?filename=1018116823.nh&dbcode=CMFD&dbname=CMFDREF">中文人物属性槽填充技术的研究与实现</a></p>
<p><a target="_blank" rel="noopener" href="http://www.nlpr.ia.ac.cn/2012papers/gnhy/nh4.pdf">面向非结构化文本的开放式实体属性抽取</a></p>
<p><a target="_blank" rel="noopener" href="http://gb.oversea.cnki.net/KCMS/detail/detail.aspx?filename=XDQB201810009&dbcode=CJFD&dbname=CJFDTEMP">实体—属性抽取的GRU+CRF方法</a></p>
<h2 id="5-参考资源"><a href="#5-参考资源" class="headerlink" title="5. 参考资源"></a>5. 参考资源</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/69362160">医疗健康文本的关系抽取和属性抽取</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/50584383">属性和实体抽取（传统方法）</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/10/30/%E5%B1%9E%E6%80%A7%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-关系抽取-学术界" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96-%E5%AD%A6%E6%9C%AF%E7%95%8C/">关系抽取-学术界</a>
    </h1>
  

        
        <a href="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96-%E5%AD%A6%E6%9C%AF%E7%95%8C/" class="archive-article-date">
  	<time datetime="2021-10-30T14:04:36.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-10-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="关系抽取调研——学术界"><a href="#关系抽取调研——学术界" class="headerlink" title="关系抽取调研——学术界"></a>关系抽取调研——学术界</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><p><a href="#1-%E4%BB%BB%E5%8A%A1">1. 任务</a></p>
<ul>
<li><a href="#11-%E4%BB%BB%E5%8A%A1%E5%AE%9A%E4%B9%89">1.1. 任务定义</a></li>
<li><a href="#12-%E6%95%B0%E6%8D%AE%E9%9B%86">1.2. 数据集</a></li>
<li><a href="#13-%E8%AF%84%E6%B5%8B%E6%A0%87%E5%87%86">1.3. 评测标准</a></li>
<li><a href="#14-SOTA">1.4. SOTA</a></li>
</ul>
</li>
<li><p><a href="#2-%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93">2. 方法总结</a></p>
<ul>
<li><p><a href="#21-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%BC%8F%E6%8C%96%E6%8E%98%E7%9A%84%E6%96%B9%E6%B3%95">2.1. 基于模式挖掘的方法</a></p>
<ul>
<li><a href="#211-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E6%9D%BF%E5%8C%B9%E9%85%8D%E7%9A%84%E6%96%B9%E6%B3%95">2.1.1. 基于模板匹配的方法</a></li>
<li><a href="#212-%E5%9F%BA%E4%BA%8E%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95">2.1.2. 基于依存句法的方法</a></li>
</ul>
</li>
<li><p><a href="#22-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">2.2. 监督学习</a></p>
<ul>
<li><a href="#221-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">2.2.1. 机器学习</a><ul>
<li><a href="#2211-%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E7%9A%84%E6%96%B9%E6%B3%95">2.2.1.1. 基于特征向量的方法</a></li>
<li><a href="#2212-%E5%9F%BA%E4%BA%8E%E6%A0%B8%E5%87%BD%E6%95%B0%E7%9A%84%E6%96%B9%E6%B3%95">2.2.1.2. 基于核函数的方法</a></li>
</ul>
</li>
<li><a href="#222-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">2.2.2. 深度学习</a><ul>
<li><a href="#2221-Pipeline%EF%BC%88%E7%AE%A1%E9%81%93%E5%BC%8F%EF%BC%89">2.2.2.1. Pipeline（管道式）</a></li>
<li><a href="#2222-Joint%EF%BC%88%E8%81%94%E5%90%88%E6%8A%BD%E5%8F%96%E5%BC%8F%EF%BC%89">2.2.2.2. Joint（联合抽取式）</a></li>
<li><a href="#2223-%E8%BF%9C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">2.2.2.3. 远监督学习</a></li>
</ul>
</li>
</ul>
</li>
<li><p><a href="#23-%E5%8D%8A%E7%9B%91%E7%9D%A3/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%96%B9%E6%B3%95">2.3. 半监督&#x2F;无监督方法</a></p>
<ul>
<li>2.3.1. Bootstrapping</li>
<li>2.3.2. 联合训练</li>
<li>2.3.3. 标签传播</li>
<li>2.3.4. 关系实例聚类和关系类型词选择</li>
</ul>
</li>
</ul>
</li>
<li><p><a href="#4-paper-list">4. Paper List</a></p>
<ul>
<li><p><a href="#11-%E8%AE%BA%E6%96%87%E5%88%97%E8%A1%A8">4.1. 论文列表</a></p>
<ul>
<li><a href="#411-%E7%9B%91%E7%9D%A3%E7%B1%BB%E6%96%B9%E6%B3%95">4.1.1. 监督类方法</a></li>
<li><a href="#412-%E8%BF%9C%E7%9B%91%E7%9D%A3%E6%96%B9%E6%B3%95">4.1.2. 远监督方法</a></li>
</ul>
</li>
<li><p>4.2. 论文解读</p>
</li>
</ul>
</li>
<li><p><a href="#5-%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE">5.相关文献</a></p>
</li>
</ul>
<h2 id="1-任务"><a href="#1-任务" class="headerlink" title="1. 任务"></a>1. 任务</h2><h3 id="1-1-任务定义"><a href="#1-1-任务定义" class="headerlink" title="1.1. 任务定义"></a>1.1. 任务定义</h3><p>自动识别句子中实体之间具有的某种语义关系。根据参与实体的多少可以分为二元关系抽取（两个实体）和多元关系抽取（三个及以上实体）。</p>
<p>通过关注两个实体间的语义关系，可以得到（subject, relation, object）三元组，其中subject和object表示两个实体，relation表示实体间的语义关系。</p>
<p>根据处理数据源的不同，关系抽取可以分为以下三种：</p>
<ul>
<li>面向结构化文本的关系抽取：包括表格文档、XML文档、数据库数据等</li>
<li>面向非结构化文本的关系抽取：纯文本</li>
<li>面向半结构化文本的关系抽取：介于结构化和非结构化之间</li>
</ul>
<p>根据抽取文本的范围不同，关系抽取可以分为以下两种：</p>
<ul>
<li>句子级关系抽取：从一个句子中判别两个实体间是何种语义关系</li>
<li>语料（篇章）级关系抽取：不限定两个目标实体所出现的上下文</li>
</ul>
<p>根据所抽取领域的划分，关系抽取又可以分为以下两种：</p>
<ul>
<li>限定域关系抽取：在一个或者多个限定的领域内对实体间的语义关系进行抽取，限定关系的类别，可看成是一个文本分类任务</li>
<li>开放域关系抽取：不限定关系的类别</li>
</ul>
<p>限定域关系抽取方法：</p>
<ul>
<li>基于模板的关系抽取方法：通过人工编辑或者学习得到的模板对文本中的实体关系进行抽取和判别，受限于模板的质量和覆盖度，可扩张性不强</li>
<li>基于机器学习的关系抽取方法：将关系抽取看成是一个分类问题</li>
</ul>
<h3 id="1-2-数据集"><a href="#1-2-数据集" class="headerlink" title="1.2. 数据集"></a>1.2. 数据集</h3><ul>
<li><p><strong>ACE 2005</strong></p>
<p><strong>数据集简介</strong>：ACE2005语料库是语言数据联盟(LDC)发布的由实体，关系和事件注释组成的各种类型的数据，包括英语，阿拉伯语和中文培训数据，目标是开发自动内容提取技术，支持以文本形式自动处理人类语言。ACE语料解决了五个子任务的识别：entities、values、temporal expressions、relations and events。这些任务要求系统处理文档中的语言数据，然后为每个文档输出有关其中提到或讨论的实体，值，时间表达式，关系和事件的信息。</p>
<p><strong>获取方式</strong>：数据集收费，需在LDC联盟的官网上注册再购买，<a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/signup">LDC账号注册地址</a>       <a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/LDC2006T06">ACE 2005 下载地址</a></p>
</li>
<li><p><strong>TACRED</strong></p>
<p><strong>数据集简介</strong>：TACRED(TAC Relation Extraction Dataset)是一个拥有106264条实例的大规模关系抽取数据集，这些数据来自于每年的<a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/LDC2018T03">TAC KBP（TAC Knowledge Base Population）</a>比赛使用的语料库中的新闻专线和网络文本。包含了41关系类型，此外若句子无定义关系，被标注成no_relation类型。数据集的详细介绍可以访问<a target="_blank" rel="noopener" href="https://nlp.stanford.edu/projects/tacred/">TACRED文档</a></p>
<p><strong>获取方式</strong>：数据集收费，需在LDC联盟官网注册会员再购买 <a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/signup">LDC账号注册地址</a>      <a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/LDC2018T24">TACRED 下载地址</a></p>
</li>
<li><p><strong>SemEval2010_task8</strong> </p>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20201005102419115.png" alt="image-20201005102419115"></p>
<p><strong>数据集简介</strong>:对于给定了的句子和两个做了标注的名词，从给定的关系清单中选出最合适的关系。数据集一共9种关系类别数，此外包含一类Other关系，含有6674实例数量。</p>
<p><strong>获取方式</strong>: <a target="_blank" rel="noopener" href="http://semeval2.fbk.eu/semeval2.php?location=data">原始数据</a></p>
</li>
<li><p><strong>FewRel</strong></p>
<p>数据集简介:FewRel是目前最大规模的精标注关系抽取数据集，由孙茂松教授领导的清华大学自然语言处理实验室发布。一共100种关系类别数，含有70000实例数量。</p>
<p>获取方式：<a target="_blank" rel="noopener" href="https://thunlp.github.io/fewrel.html">FewRel 网站地址</a>   <a target="_blank" rel="noopener" href="http://aclweb.org/anthology/D18-1514">论文地址</a></p>
</li>
<li><p><strong>NYT10</strong> </p>
<p><strong>NYT-10</strong>数据集文本来源于纽约时报，命名实体是通过 Stanford NER 工具并结合 Freebase 知识库进行标注的。实体对之间的关系是链接Freebase知识库中的关系，结合远监督方法所得到。该数据集共含有53种关系类型，包括特殊关系类型NA，即头尾实体无关系。</p>
<p><strong>获取方式</strong>:<a href="https://link.zhihu.com/?target=https://cloud.tsinghua.edu.cn/f/11391e48b72749d8b60a/?dl=1">原始数据</a></p>
</li>
</ul>
<p>获取更多关系抽取数据集，可访问此处<a target="_blank" rel="noopener" href="https://github.com/davidsbatista/Annotated-Semantic-Relationships-Datasets">Annotated-Semantic-Relationships-Datasets</a></p>
<h3 id="1-3-评测标准"><a href="#1-3-评测标准" class="headerlink" title="1.3. 评测标准"></a>1.3. 评测标准</h3><p><strong>二分类</strong>：</p>
<p>Accuracy &#x3D; (预测正确的样本数)&#x2F;(总样本数)&#x3D;(TP+TN)&#x2F;(TP+TN+FP+FN)</p>
<p>Precision &#x3D; (预测为正例且正确预测的样本数)&#x2F;(所有预测为正例的样本数) &#x3D; TP&#x2F;(TP+FP)</p>
<p>Recall &#x3D; (预测为正例且正确预测的样本数)&#x2F;(所有真实情况为正例的样本数) &#x3D; TP&#x2F;(TP+FN)</p>
<p>F1 &#x3D; 2 * (Precision * Recall) &#x2F; (Precision + Recall )</p>
<p><strong>多分类</strong>：</p>
<p>Macro Average </p>
<p>多类别（N类） F1&#x2F;P&#x2F;R的计算，即计算N个类别的F1&#x2F;P&#x2F;R，每次计算以当前类别为正例，其他所有类别为负例，最终将各类别结果求和并除以类别数取平均。</p>
<p>Micro Average</p>
<p>统计当前类别的TP、TN、FP、FN数量，再将该四类样本数各自求和作为新的TP、TN、FP、FN，计算F1&#x2F;P&#x2F;R公式同二分类。</p>
<p><strong>P@N（最高置信度预测精度）</strong>:</p>
<p>通常在远监督关系抽取中使用到，由于知识库所含关系实例的不完善，会出现高置信度包含关系实例的实体对被叛为负例，从而低估了系统正确率。此时可以采用人工评价，将预测结果中知识库已包含的三元组移除，然后人工判断抽取关系实例是否正确，按照top N的准确率对抽取效果进行评价。</p>
<h3 id="1-4-SOTA"><a href="#1-4-SOTA" class="headerlink" title="1.4. SOTA"></a>1.4. SOTA</h3><p>Relation Extraction on <strong>TACRED</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>average F1</th>
<th>论文题目</th>
<th>年份</th>
<th>论文链接</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td>BERTEM+MTB</td>
<td>71.5</td>
<td>Matching the Blanks: Distributional Similarity for Relation Learning</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.03158v1.pdf">https://arxiv.org/pdf/1906.03158v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/plkmo/BERT-Relation-Extraction">https://github.com/plkmo/BERT-Relation-Extraction</a></td>
</tr>
<tr>
<td>KnowBert-W+W</td>
<td>71.5</td>
<td>Knowledge Enhanced Contextual Word Representations</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.04164v2.pdf">https://arxiv.org/pdf/1909.04164v2.pdf</a></td>
<td></td>
</tr>
<tr>
<td>DG-SpanBERT</td>
<td>71.5</td>
<td>Efficient long-distance relation extraction with DG-SpanBERT</td>
<td>2020</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.03636v1.pdf">https://arxiv.org/pdf/2004.03636v1.pdf</a></td>
<td></td>
</tr>
<tr>
<td>SpanBERT</td>
<td>70.8</td>
<td>SpanBERT: Improving Pre-training by Representing and Predicting Spans</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1907.10529v3.pdf">https://arxiv.org/pdf/1907.10529v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/SpanBERT">https://github.com/facebookresearch/SpanBERT</a></td>
</tr>
<tr>
<td>R-BERT</td>
<td>69.4</td>
<td>Enriching Pre-trained Language Model with Entity Information for Relation Classification</td>
<td>2020</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.08284v1.pdf">https://arxiv.org/pdf/1905.08284v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/wang-h/bert-relation-classification">https://github.com/wang-h/bert-relation-classification</a></td>
</tr>
<tr>
<td>C-GCN + PA-LSTM</td>
<td>68.2</td>
<td>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction</td>
<td>2018</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.10185v1.pdf">https://arxiv.org/pdf/1809.10185v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/qipeng/gcn-over-pruned-trees">https://github.com/qipeng/gcn-over-pruned-trees</a></td>
</tr>
</tbody></table>
<p>Relation Extraction on <strong>SemEval-2010 Task 8</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>average F1</th>
<th>论文题目</th>
<th>年份</th>
<th>论文链接</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td>Skeleton-Aware BERT</td>
<td>90.36</td>
<td>Enhancing Relation Extraction Using Syntactic Indicators and Sentential Contexts</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1912.01858v1.pdf">https://arxiv.org/pdf/1912.01858v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/wang-h/bert-relation-classification">https://github.com/wang-h/bert-relation-classification</a></td>
</tr>
<tr>
<td>EPGNN</td>
<td>90.2</td>
<td>Improving Relation Classification by Entity Pair Graph</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v101/zhao19a/zhao19a.pdf">http://proceedings.mlr.press/v101/zhao19a/zhao19a.pdf</a></td>
<td></td>
</tr>
<tr>
<td>BERTEM+MTB</td>
<td>89.5</td>
<td>Matching the Blanks: Distributional Similarity for Relation Learning</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.03158v1.pdf">https://arxiv.org/pdf/1906.03158v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/plkmo/BERT-Relation-Extraction">https://github.com/plkmo/BERT-Relation-Extraction</a></td>
</tr>
<tr>
<td>R-BERT</td>
<td>89.25</td>
<td>Enriching Pre-trained Language Model with Entity Information for Relation Classification</td>
<td>2020</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.08284v1.pdf">https://arxiv.org/pdf/1905.08284v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/wang-h/bert-relation-classification">https://github.com/wang-h/bert-relation-classification</a></td>
</tr>
<tr>
<td>KnowBert-W+W</td>
<td>89.1</td>
<td>Knowledge Enhanced Contextual Word Representations</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.04164v2.pdf">https://arxiv.org/pdf/1909.04164v2.pdf</a></td>
<td></td>
</tr>
<tr>
<td>Entity-Aware BERT</td>
<td>89</td>
<td>Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1902.01030v2.pdf">https://arxiv.org/pdf/1902.01030v2.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/helloeve/mre-in-one-pass">https://github.com/helloeve/mre-in-one-pass</a></td>
</tr>
</tbody></table>
<p>Relation Extraction on <strong>ACE 2005</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>RELATION F1</th>
<th>ENTITY F1</th>
<th>SENTENCE ENCODER</th>
<th>论文题目</th>
<th>年份</th>
<th>论文链接</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td>MRC4ERE++</td>
<td>62.1</td>
<td>85.5</td>
<td>BERT base</td>
<td>Asking Effective and Diverse Questions: A Machine Reading Comprehension based Framework for Joint Entity-Relation Extraction</td>
<td>2020</td>
<td><a target="_blank" rel="noopener" href="https://www.ijcai.org/Proceedings/2020/0546.pdf">https://www.ijcai.org/Proceedings/2020/0546.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/TanyaZhao/MRC4ERE">https://github.com/TanyaZhao/MRC4ERE</a></td>
</tr>
<tr>
<td>Multi-turn QA</td>
<td>60.2</td>
<td>84.8</td>
<td>BERT base</td>
<td>Entity-Relation Extraction as Multi-Turn Question Answering</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.05529v4.pdf">https://arxiv.org/pdf/1905.05529v4.pdf</a></td>
<td></td>
</tr>
<tr>
<td>MRT</td>
<td>59.6</td>
<td>83.6</td>
<td>biLSTM</td>
<td>Extracting Entities and Relations with Joint Minimum Risk Training</td>
<td>2018</td>
<td><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D18-1249">https://www.aclweb.org/anthology/D18-1249</a></td>
<td></td>
</tr>
<tr>
<td>GCN</td>
<td>59.1</td>
<td>84.2</td>
<td>biLSTM</td>
<td>Joint Type Inference on Entities and Relations via Graph Convolutional Networks</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P19-1131">https://www.aclweb.org/anthology/P19-1131</a></td>
<td></td>
</tr>
<tr>
<td>Global</td>
<td>57.5</td>
<td>83.6</td>
<td>biLSTM</td>
<td>End-to-End Neural Relation Extraction with Global Optimization</td>
<td>2017</td>
<td><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D17-1182">https://www.aclweb.org/anthology/D17-1182</a></td>
<td></td>
</tr>
<tr>
<td>SPTree</td>
<td>55.6</td>
<td>83.4</td>
<td>biLSTM</td>
<td>End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures</td>
<td>2016</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1601.00770v3.pdf">https://arxiv.org/pdf/1601.00770v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/tticoin/LSTM-ER">https://github.com/tticoin/LSTM-ER</a></td>
</tr>
</tbody></table>
<p>Relation Extraction on <strong>ACE 2004</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>RELATION F1</th>
<th>ENTITY F1</th>
<th>论文题目</th>
<th>年份</th>
<th>论文链接</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td>DYGIE</td>
<td>59.7</td>
<td>87.4</td>
<td>A General Framework for Information Extraction using Dynamic Span Graphs</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.03296v1.pdf">https://arxiv.org/pdf/1904.03296v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/luanyi/DyGIE">https://github.com/luanyi/DyGIE</a></td>
</tr>
<tr>
<td>Multi-turn QA</td>
<td>49.4</td>
<td>83.6</td>
<td>Entity-Relation Extraction as Multi-Turn Question Answering</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.05529v4.pdf">https://arxiv.org/pdf/1905.05529v4.pdf</a></td>
<td></td>
</tr>
<tr>
<td>SPTree</td>
<td>48.4</td>
<td>81.8</td>
<td>End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures</td>
<td>2016</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1601.00770v3.pdf">https://arxiv.org/pdf/1601.00770v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/tticoin/LSTM-ER">https://github.com/tticoin/LSTM-ER</a></td>
</tr>
<tr>
<td>multi-head + AT</td>
<td>47.45</td>
<td>81.64</td>
<td>Adversarial training for multi-context joint entity and relation extraction</td>
<td>2018</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1808.06876v3.pdf">https://arxiv.org/pdf/1808.06876v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/bekou/multihead_joint_entity_relation_extraction">https://github.com/bekou/multihead_joint_entity_relation_extraction</a></td>
</tr>
<tr>
<td>multi-head</td>
<td>47.14</td>
<td>81.16</td>
<td>Joint entity recognition and relation extraction as a multi-head selection problem</td>
<td>2018</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1804.07847v3.pdf">https://arxiv.org/pdf/1804.07847v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/bekou/multihead_joint_entity_relation_extraction">https://github.com/bekou/multihead_joint_entity_relation_extraction</a></td>
</tr>
<tr>
<td>Attention</td>
<td>45.7</td>
<td>79.6</td>
<td>Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees</td>
<td>2017</td>
<td><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P17-1085">https://www.aclweb.org/anthology/P17-1085</a></td>
<td></td>
</tr>
</tbody></table>
<p>Relation Extraction on <strong>NYT</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>average F1</th>
<th>论文题目</th>
<th>年份</th>
<th>论文链接</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td>REDN</td>
<td>89.8</td>
<td>Downstream Model Design of Pre-trained Language Model for Relation Extraction Task</td>
<td>2020</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.03786v1.pdf">https://arxiv.org/pdf/2004.03786v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/slczgwh/REDN">https://github.com/slczgwh/REDN</a></td>
</tr>
<tr>
<td>CASREL</td>
<td>89.6</td>
<td>A Novel Cascade Binary Tagging Framework</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.03227v4.pdf">https://arxiv.org/pdf/1909.03227v4.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/weizhepei/CasRel">https://github.com/weizhepei/CasRel</a></td>
</tr>
<tr>
<td>HBT</td>
<td>89.5</td>
<td>A Novel Cascade Binary Tagging Framework for Relational Triple Extraction</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.03227v4.pdf">https://arxiv.org/pdf/1909.03227v4.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/weizhepei/CasRel">https://github.com/weizhepei/CasRel</a></td>
</tr>
<tr>
<td>WDec</td>
<td>84.4</td>
<td>Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.09886v1.pdf">https://arxiv.org/pdf/1911.09886v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/nusnlp/PtrNetDecoding4JERE">https://github.com/nusnlp/PtrNetDecoding4JERE</a></td>
</tr>
<tr>
<td>ETL-Span</td>
<td>78.0</td>
<td>Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.04273v3.pdf">https://arxiv.org/pdf/1909.04273v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/yubowen-ph/JointER">https://github.com/yubowen-ph/JointER</a></td>
</tr>
<tr>
<td>CopyRE’ OneDecoder</td>
<td>72.2</td>
<td>CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations with Multi-Task Learning</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.10438v1.pdf">https://arxiv.org/pdf/1911.10438v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/WindChimeRan/CopyMTL">https://github.com/WindChimeRan/CopyMTL</a></td>
</tr>
</tbody></table>
<p>Relation Extraction on <strong>CoNLL04</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>RELATION F1</th>
<th>ENTITY F1</th>
<th>论文题目</th>
<th>年份</th>
<th>论文链接</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td>SpERT</td>
<td>71.47</td>
<td>88.94</td>
<td>Span-based Joint Entity and Relation Extraction with Transformer Pre-training</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.07755v3.pdf">https://arxiv.org/pdf/1909.07755v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/markus-eberts/spert">https://github.com/markus-eberts/spert</a></td>
</tr>
<tr>
<td>Multi-turn QA</td>
<td>68.9</td>
<td>87.8</td>
<td>Entity-Relation Extraction as Multi-Turn Question Answering</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.05529v4.pdf">https://arxiv.org/pdf/1905.05529v4.pdf</a></td>
<td></td>
</tr>
<tr>
<td>Global</td>
<td>67.8</td>
<td>85.6</td>
<td>End-to-End Neural Relation Extraction with Global Optimization</td>
<td>2017</td>
<td><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D17-1182">https://www.aclweb.org/anthology/D17-1182</a></td>
<td></td>
</tr>
<tr>
<td>Biaffine attention</td>
<td>64.40</td>
<td>86.20</td>
<td>End-to-end neural relation extraction using deep biaffine attention</td>
<td>2018</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.11275v1.pdf">https://arxiv.org/pdf/1812.11275v1.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/datquocnguyen/jointRE">https://github.com/datquocnguyen/jointRE</a></td>
</tr>
<tr>
<td>Relation-Metric with AT</td>
<td>62.29</td>
<td>84.15</td>
<td>Neural Metric Learning for Fast End-to-End Relation Extraction</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.07458v4.pdf">https://arxiv.org/pdf/1905.07458v4.pdf</a></td>
<td></td>
</tr>
<tr>
<td>multi-head</td>
<td>62.04</td>
<td>83.9</td>
<td>Joint entity recognition and relation extraction as a multi-head selection problem</td>
<td>2018</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1804.07847v3.pdf">https://arxiv.org/pdf/1804.07847v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/bekou/multihead_joint_entity_relation_extraction">https://github.com/bekou/multihead_joint_entity_relation_extraction</a></td>
</tr>
</tbody></table>
<p>Relation Extraction on <strong>FewRel</strong>：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>average F1</th>
<th>论文题目</th>
<th>年份</th>
<th>论文链接</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td>ERNIE</td>
<td>88.32</td>
<td>ERNIE: Enhanced Language Representation with Informative Entities</td>
<td>2019</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.07129v3.pdf">https://arxiv.org/pdf/1905.07129v3.pdf</a></td>
<td><a target="_blank" rel="noopener" href="https://github.com/thunlp/ERNIE">https://github.com/thunlp/ERNIE</a></td>
</tr>
</tbody></table>
<h2 id="2-方法总结"><a href="#2-方法总结" class="headerlink" title="2. 方法总结"></a>2. 方法总结</h2><h3 id="2-1-基于模式挖掘的方法"><a href="#2-1-基于模式挖掘的方法" class="headerlink" title="2.1. 基于模式挖掘的方法"></a>2.1. 基于模式挖掘的方法</h3><h4 id="2-1-1-基于模板匹配的方法"><a href="#2-1-1-基于模板匹配的方法" class="headerlink" title="2.1.1. 基于模板匹配的方法"></a>2.1.1. 基于模板匹配的方法</h4><p><strong>模板匹配</strong>：在关系分类中应用广泛。对于给定实体对的一段文本，基于现有模板库进行上下文匹配。若结果满足模板对应关系类别，则将该关系类别作为实体对之间的关系。</p>
<p>常见的模板匹配方法主要包括：</p>
<ul>
<li><strong>人工模板</strong>：常见于判断实体间存在的上下位关系。基本出发点是统计和总结关系模式，通过专家定义寻找关系在上下文中表达的字符，语法及语义特征，将此作为模式与文本进行匹配，进行关系实例的获取。</li>
<li><strong>统计生成</strong>：无须人工构建，主要基于搜索引擎进行统计模板抽取。具体地，将已知实体对作为查询语句，抓取搜索引擎返回的前n个结果文档并保留包含该实体对的句子集合，寻找包含实体对的最长字串作为统计模板，保留置信度较高的模板用于关系分类。</li>
</ul>
<p> (<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/C92-2082.pdf">Marti A. Hearst 1992</a>) <a href="#refer-anchor-1"><sup>[1]</sup></a>在该文中提出一种从不受限制的文本中自动获得下位词法关系的方法，用于提取分类关系is-a的实例：</p>
<!-- ![image-20201009171753511](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/Hearst1992.png) -->
<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96-%E5%AD%A6%E6%9C%AF%E7%95%8C/Hearst1992.png" class="" title="img">

<h4 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h4><p>句子中上下位关系，比如hyponym(China; Asia countries)。从下面两个句子中都可以抽取出这种关系：</p>
<ul>
<li>Asia countries, especially China, Japan, and India…</li>
<li>Asia countries, such as China, Japan, and India…</li>
</ul>
<p>两个实体之间的especially和such as可以看做这种关系的特征。通过寻找更多表达这种关系的句子，构造规则模板，即可用于抽取构成上下位关系的实体，从而发现新的三元组。</p>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>优点：</p>
<ul>
<li>该方法准确率较高。</li>
<li>从某种意义上说，这是一种假设的工作，Hearst文中没有给出实验结果，但它对追随者影响很大，是之后Bootstraping方法的开篇之作。</li>
</ul>
<p>缺点：</p>
<ul>
<li>召回率较低，且关系类别有限，仅仅包含is-a的关系。</li>
<li>适用性有限，难以移植</li>
</ul>
<h4 id="2-1-2-基于依存句法"><a href="#2-1-2-基于依存句法" class="headerlink" title="2.1.2. 基于依存句法"></a>2.1.2. 基于依存句法</h4><p>基于NLP工具（常见的有Stanford CoreNLP、spaCy、LTP、HanLP等）获取句子相关特征，对处理结果一般进行如下处理：</p>
<ol>
<li>输入文本完成分词、词性标注、命名实体识别、依存分析等处理步骤。</li>
<li>基于语法规则抽取出相关语法信息，如 “主谓宾”、“定状补”等，从而得到句子中各成分之间的联系和关系。</li>
<li>利用各成分之间相互关联关系总结出诸如定中关系，定语后置关系等抽取规则。</li>
<li>设定规则模板，并根据规则对抽取结果进行严格测试与调优。</li>
</ol>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><p>下面介绍一组基于LTP（语言技术平台）工具进行规则抽取三元组的例子：</p>
<ul>
<li><p>输入文本：杨燕萍，女，中国共产党党员，系江西省第十一届政协主席许爱民的妻子。</p>
</li>
<li><p>经LTP得出依存句法分析结果：</p>
<!-- ![image-20201009163758374](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E7%A4%BA%E4%BE%8B.png) --></li>
</ul>


<p>  ​                                                                                                  依存句法分析结果示例</p>
  <!-- ![image-20201009164128481](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/%E5%8F%A5%E6%B3%95%E5%85%B3%E7%B3%BB%E7%B1%BB%E5%9E%8B.png) -->



<p>  ​                                                                                                          依存句法关系类型说明</p>
<p>  由图示可知，可以以谓语动词为出发点构建规则，对节点上词性以及边上的关系进行设定。当前句子核心谓词是“系”，从前向后遍历句子解析结果可以从“主席”开始分析，由于“主席”与左右两侧词汇均构成定中关系且两侧词汇均被识别为命名实体。由此，可以提取出一项（政协，主席，许爱民）定中关系三元组。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>手写规则的 <strong>优点</strong> ：</p>
<ul>
<li>人工设定规则，准确率高(high-precision)</li>
<li>结合专家知识，进行特定领域定制</li>
<li>构建简单，适合小规模关系类别数据</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>规则总结无法穷尽，导致低召回率(low-recall)</li>
<li>所有关系类别须定义相关规则pattern，耗时耗力</li>
<li>难以维护及跨领域移植</li>
</ul>
<h3 id="2-2-监督学习"><a href="#2-2-监督学习" class="headerlink" title="2.2. 监督学习"></a>2.2. 监督学习</h3><h4 id="2-2-1-机器学习"><a href="#2-2-1-机器学习" class="headerlink" title="2.2.1. 机器学习"></a>2.2.1. 机器学习</h4><h4 id="2-2-1-1-基于特征向量的方法"><a href="#2-2-1-1-基于特征向量的方法" class="headerlink" title="2.2.1.1. 基于特征向量的方法"></a>2.2.1.1. 基于特征向量的方法</h4><p>基于特征向量的方法是一种简单且行之有效 的关系抽取运用。其主要思想为：给定关系句子实例，从上下文中提取出具有类间区分度的特征（如词法信息，语法信息等），构造形成多维度加权特征向量，选取合适的分类器进行关系抽取模型训练。</p>
<p>基于特征向量的方法需要解决的三个基本问题：特征项选取，特征权重计算和分类器选择。</p>
<ul>
<li><p>特征项。作为向量模型的骨架，它需要包含足够的语义信息来表征自然文本，又需要在语义关系间具有良好的区分度。常见的特征项有：词法、实体、句法、语义及上下文结构化信息等。</p>
</li>
<li><p>特征权重计算。众多候选特征项，对最终关系分类的贡献度不可能完全一样，比如实体间语义关系往往比实体词汇、句子长度等特征更加重要。因此，需要进行特征重要性权重计算。这里提供两种权重方法计算思路：一、公式计算权值并排序，如布尔权重、特征频度<sup>[5]</sup>。二、基于优化算法进行最优权向量搜索<sup>[6]</sup></p>
</li>
<li><p>分类器选取。特征向量构造完毕后，下一步便是选取合适的分类器。下面介绍两种具有代表性的分类器：</p>
<ul>
<li><p><strong>最大熵模型</strong>（<strong>Maximum Entropy Model</strong>）</p>
<p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P04-3022/">Kambhatla 2004</a><sup>[2]</sup>基于文本中实体词，实体类型，实体引用类型、语法以及句法树在内的多种特征，采用最大熵分类器，对不同特征叠加后进行了实验对比，并在ACE RDC2003语料的子类关系中获得了52.8的F1值，表明多层面语言学特征能有效提升关系分类模型的效果。</p>
<!-- ![image-20201010130214309](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/Kambhatla2004.png) -->
<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96-%E5%AD%A6%E6%9C%AF%E7%95%8C/Kambhatla2004.png" class="" title="img">
</li>
<li><p><strong>支持向量机(SVM)</strong></p>
<p><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P05-1053/">Zhou et al.,2005</a><sup>[3]</sup>在Kambhatla前期基础上，融入基本的词组块信息特征组合，基于SVM获得了55.5的F1性能，并得出实体类别特征对于关系抽取结果提升最大的结论。<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P05-1052/">Zhao et al.，2005</a><sup>[4]</sup>引用了文字特征，语句解析和深层语法依存特征等组合。<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N07-1015/">Jiang et al.,2007</a><sup>[5]</sup>选取文本词序列、句法、依存关系等特征组合，以不同类别特征对抽取结果贡献度进行了评估，他们总结出在这些类别特征中选取最基本的单位特征便可以有效的提升关系抽取的性能，而过于复杂的特征带来的性能提升效果则一般。</p>
</li>
</ul>
</li>
</ul>
<p><strong>小结：</strong></p>
<p>基于特征向量的方法是关系抽取中最常见的方法，特征工程是该方法核心。研究者启发式地以多层次语言特征为切入点，并构造特征向量，结合分类器训练，可以取得不错的效果。但该方法现如今难以寻找有效新特征，性能提升较为有限。</p>
<h4 id="2-2-1-2-基于核函数的方法"><a href="#2-2-1-2-基于核函数的方法" class="headerlink" title="2.2.1.2. 基于核函数的方法"></a>2.2.1.2. 基于核函数的方法</h4><p>针对特征提取具有的局限性，便有研究者另辟蹊径，使用核函数的方法进行关系抽取。基于核函数的方法无需人为构造显性特征，而是以输入文本实例的字符串或者是句法分析树结构作为输入，通过计算任意两个输入对象间的核相似度函数来训练分类模型。基于核函数的方法通过核函数映射综合了更多方面的知识信息，使实体间关系表示更加灵活。核函数类型众多，有包含诸如多项式核函数，向量空间核函数，P-光谱核函数，全序列核函数等。基于核函数的方法灵活性较高，对于多个不同个体核函数可以进行复合，从而得到针对具体任务的核函数。</p>
<p><strong>方法原理</strong>：在初始特征空间下，核函数将该空间里的数据点映射到一个新的特征空间下，在该空间中训练线性分类器。其本质是将句子潜在的隐式特征向量投影到新的特征空间，并通过计算投影的内积来表示输入空间特征向量的相似性，最终达到判定实体间关系类别相似性的效果。</p>
<p>基于核函数的方法抽取关系一般步骤：</p>
<ol>
<li>针对句子中隐含的特征信息，选用合适的解析结构，如语法树等进行语句剖析；</li>
<li>在此基础上选择合适的基础核函数，计算解析结构中成分之间的相似性；</li>
<li>在基础核函数之上，将多个核函数复合，以充分利用各种隐式特征，提高分类精度。</li>
</ol>
<ul>
<li><p>浅层树核（<a target="_blank" rel="noopener" href="https://jmlr.org/papers/v3/zelenko03a.html">Zelenko，2003</a>）<sup>[6]</sup></p>
</li>
<li><p>依存树核（<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P04-1054/">Culotta et al., 2004</a>）<sup>[7]</sup></p>
</li>
<li><p>最短依存树核（<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/H05-1091/">Bunescu et al., 2005</a>）<sup>[8]</sup></p>
</li>
<li><p>卷积树核（<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P06-1104/">Zhang et al., 2006</a><sup>[9]</sup>；<a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D07-1076/">Zhou et al., 2007</a><sup>[10]</sup>）</p>
</li>
<li><p>其他的还有诸如</p>
<ul>
<li><p>constituent parse trees [Collins &amp; Duffy, 2001] </p>
</li>
<li><p>string sequencies [Cancedda &amp; al., 2003]</p>
</li>
<li><p>directed acyclic graphs [Suzuki &amp; al., 2003]</p>
</li>
<li><p>dependency parse trees [Moschitti, 2006]</p>
</li>
<li><p>feature-enriched&#x2F;semantic tree kernel [Plank &amp; Moschitti,2013; Sun &amp; Han, 2014]</p>
</li>
</ul>
</li>
</ul>
<p><strong>小结</strong>:</p>
<p>基于核函数的方法可以规避构造基于向量方法中显式特征集合，且更能够充分利用句子的长距离特征。然而核方法将多个不同核函数符合后，虽然可以表达高纬度或无穷维度特征空间，但也导致该方法学习和训练速度 过程较为缓慢，对于大规模数据抽取场景耗费时空代价巨大。</p>
<p>二者比较</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>特征项</th>
<th>特征表示方法</th>
<th>核心步骤</th>
</tr>
</thead>
<tbody><tr>
<td>基于特征向量的方法</td>
<td>词、词性、上下文结构信息、依存分析、句法树等</td>
<td>显式</td>
<td>特征工程</td>
</tr>
<tr>
<td>基于核函数的方法</td>
<td>依存树核、卷积树核等</td>
<td>隐式高维</td>
<td>设计核函数计算</td>
</tr>
</tbody></table>
<h4 id="2-2-2-深度学习"><a href="#2-2-2-深度学习" class="headerlink" title="2.2.2. 深度学习"></a>2.2.2. 深度学习</h4><h5 id="2-2-2-1-Pipeline（管道式）"><a href="#2-2-2-1-Pipeline（管道式）" class="headerlink" title="2.2.2.1. Pipeline（管道式）"></a>2.2.2.1. Pipeline（管道式）</h5><p>Pipeline方法先在句子中抽取实体、而后再抽取关系。即实体识别，关系分类被视为两个独立的部分，互不干涉，但关系的识别依赖于实体识别的效果。</p>
<h5 id="2-2-2-2-Joint（联合抽取式）"><a href="#2-2-2-2-Joint（联合抽取式）" class="headerlink" title="2.2.2.2. Joint（联合抽取式）"></a>2.2.2.2. Joint（联合抽取式）</h5><p>现有联合抽取模型总体上有两大类：</p>
<p>1、共享参数联合抽取模型</p>
<p>通过共享参数（共享输入特征或者内部隐层状态）实现联合，此种方法对子模型没有限制，但是由于使用独立的解码算法，导致实体模型和关系模型之间交互不强。</p>
<p> Miwa<sup>[11]</sup>等人针对上游任务实体识别抽取出的实体对，对当前句子所对应的依存句法树上提取出能覆盖实体对的最小依存树，并基于<strong>TreeLSTM</strong>生成该子树相对应的表示向量。最终，基于子树根节点对应的<strong>TreeLSTM</strong>向量完成SoftMax关系分类。</p>
<p>Katiyar<sup>[12]</sup> 等人采取指针网络解码，指针网络实际上有R层（R为关系总数）。对当前实体查询在其位置前的所有实体（向前查询），并计算注意力得分。</p>
<p>2、联合解码抽取模型</p>
<p>为了增强实体模型和关系模型之间的交互性，由此提出了复杂的联合解码方案，但需要对子模型特征的丰富性以及联合解码的精确性之间做权衡：一方面如果设计精确的联合解码算法，往往需要对模型特征进行限制，例如用条件随机场建模，使用维特比解码算法可以得到全局最优解，但是往往需要限制特征的阶数。</p>
<p>另一方面如果使用近似解码算法，比如集束搜索，在特征方面可以抽取任意阶的特征，但是解码得到的结果是不精确的。因此，需要让算法可以在不影响子模型特征丰富性的条件下加强子模型之间的交互。</p>
<p>Zheng<sup>[13]</sup>等人对实体和关系标注框架进行了统一，直接以关系标签进行实体的BIOES标注，但该方案未考虑关系重叠问题，比如一个实体存在多种关系的情况。 Dai<sup>[14]</sup>等人针对一句话含有多种关系的场景，在含有n个token的句子中，准备n个不同标注框架。对于每个位置的token都进行一次可能的实体或关系类型标注，由此一个句子进行了n次重复编码，复杂度高。</p>
<h5 id="2-2-2-3-远监督学习"><a href="#2-2-2-3-远监督学习" class="headerlink" title="2.2.2.3. 远监督学习"></a>2.2.2.3. 远监督学习</h5><p>Distant Supervision提出主要基于假设：两个实体如果在知识库中存在某种关系，则包含该两个实体的非结构化句子均能表示出这种关系。常用的做法是通过将知识库与各非结构化文本对齐来自动构建大量训练数据，减少模型对人工标注数据的依赖，增强模型跨领域适应能力。但该假设过于肯定，导致引入大量噪声数据，且构造过程依赖于NER等工具，中间过程可能造成错误传播问题。</p>
<p>针对这些问题，目前主要有四类方法：</p>
<p>（1）将先验知识作为限制引入构造数据集的过程中。</p>
<p>（2）利用概率图模型对数据样例打分，将置信度较低的句子过滤。</p>
<p>（3）利用多示例学习进行包级别关系标注并融入句子级别的注意力机制对包内样例赋予权值。</p>
<p>（4）基于强化学习。</p>
<p>（5）基于预训练机制。</p>
<p>Zeng<sup>[15]</sup>等人针对数据标注错误和传统统计模型特征抽取出现的错误提出解决方案。在数据标注错误问题上，作者采用多示例学习的方式从训练集中提取置信度高的训练样例训练模型。在模型改进方面，作者提出 piece-wise 的卷积神经网络（PCNN）。先通过 word2vec 的 Skip-gram 模型将词表示成向量形式，与位置特征向量（句子中词语与两个实体的相对位置）进行拼接作为输入，而后通过卷积层得到 feature map。在池化层中基于两个实体位置将 feature map 分为三段进行池化，其目的是为了更好的捕获两个实体间的结构化信息。最后，通过 softmax 层进行分类。</p>
<p>Lin<sup>[16]</sup>等人在Zeng[15]的基础上，认为多示例学习虽然缓解了噪声数据过多的问题，但每次只采用包中置信度最高的样例作为该关系正例有可能损失其他句子重要信息。在模型上，作者提出基于 attention 机制的卷积神经网络模型，由原先选取置信度最高的样例改为对包中所有样例赋予句子级别权重，最终各个样例向量进行加权求和通过分类器得到关系分类结果。</p>
<p>Zhang<sup>[17]</sup> 基于Lin<sup>[8]</sup>的工作，对句子级别的注意力机制设计进行了改进，利用卷积神经网络捕获实体描述特征，用于提供更多的背景知识，最后通过计算实体间关系与句子间的相似度赋予句子不同的权重。</p>
<p>Feng<sup>[18]</sup>基于强化学习的<strong>CNN+RL</strong>模型主要构成包括样例选择器和关系分类器。其中样例选择器负责从样例中获取高质量的句子，采取强化学习方式在考虑当前句子的选择状态下选择样例；接着经过关系分类器向样例选择器反馈来改进选择策略。该方法相较之前句子级别和Bag级别的关系分类模型取得更好效果。</p>
<p>Soares<sup>[19]</sup>首次在预训练过程中引入关系分类目标，使用「BLANK」标识符来替换实体mention。该方法将样本中含有相同实体对的句子对视为正样本，反之为负样本。相较于传统的远程监督，该方法在训练中未引入关系标签，而是采用二元分类器对句子对之间进行相似度计算。结果显示在FewRel数据集上，在未进行tuning就已经超过了有监督的关系抽取结果。</p>
<h2 id="4-Paper-List"><a href="#4-Paper-List" class="headerlink" title="4. Paper List"></a>4. Paper List</h2><h3 id="4-1-论文列表"><a href="#4-1-论文列表" class="headerlink" title="4.1. 论文列表"></a>4.1. 论文列表</h3><h4 id="4-1-1-监督类方法"><a href="#4-1-1-监督类方法" class="headerlink" title="4.1.1. 监督类方法"></a>4.1.1. 监督类方法</h4><h5 id="4-1-1-1-利用语法信息的方法"><a href="#4-1-1-1-利用语法信息的方法" class="headerlink" title="4.1.1.1. 利用语法信息的方法"></a>4.1.1.1. 利用语法信息的方法</h5><table>
<thead>
<tr>
<th align="center">论文题目</th>
<th align="center">抽取任务</th>
<th align="center">关键词</th>
<th align="center">论文链接</th>
<th align="center">会议及年份</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Attention Guided Graph Convolutional Networks for Relation Extraction</td>
<td align="center">关系提取</td>
<td align="center">注意力导向图卷积网络（AGGCN）；语义依赖树；软修剪；自动学习子结构；</td>
<td align="center"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/P19-1024.pdf">https://www.aclweb.org/anthology/P19-1024.pdf</a></td>
<td align="center">ACL2019</td>
<td></td>
</tr>
<tr>
<td align="center">A Richer-but-Smarter Shortest Dependency Path with Attentive Augmentation for Relation Extraction</td>
<td align="center">关系提取</td>
<td align="center">最短依赖路径SDP；注意力模型；深度神经模型；LSTM网络；CNN</td>
<td align="center"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N19-1298">https://www.aclweb.org/anthology/N19-1298</a></td>
<td align="center">NAACL 2019</td>
<td><a target="_blank" rel="noopener" href="https://github.com/catcd/RbSP">https://github.com/catcd/RbSP</a></td>
</tr>
</tbody></table>
<h5 id="4-1-1-2-不利用语法信息的方法"><a href="#4-1-1-2-不利用语法信息的方法" class="headerlink" title="4.1.1.2. 不利用语法信息的方法"></a>4.1.1.2. 不利用语法信息的方法</h5><table>
<thead>
<tr>
<th align="center">论文题目</th>
<th align="center">抽取任务</th>
<th align="center">关键词</th>
<th align="center">论文链接</th>
<th align="center">会议及年份</th>
<th>code</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Joint Type Inference on Entities and Relations via Graph Convolutional Networks</td>
<td align="center">抽取三元组的joint任务</td>
<td align="center">实体关系联合推断；图卷积模型（GCN）；二元关系分类</td>
<td align="center"><a target="_blank" rel="noopener" href="https://pdfs.semanticscholar.org/7ce8/ce2768907421fb1a6cbfe13a8a36992721a7.pdf">https://pdfs.semanticscholar.org/7ce8/ce2768907421fb1a6cbfe13a8a36992721a7.pdf</a></td>
<td align="center">ACL2019</td>
<td></td>
</tr>
<tr>
<td align="center">GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction</td>
<td align="center">抽取三元组的joint任务</td>
<td align="center">端到端关系抽取；图卷积网络；</td>
<td align="center"><a target="_blank" rel="noopener" href="https://tsujuifu.github.io/pubs/acl19_graph-rel.pdf">https://tsujuifu.github.io/pubs/acl19_graph-rel.pdf</a></td>
<td align="center">ACL2019</td>
<td></td>
</tr>
<tr>
<td align="center">Exploiting Entity BIO Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data</td>
<td align="center">关系抽取</td>
<td align="center">BIO字符&#x2F;词嵌入；多任务体系结构；关系分类</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.08931.pdf">https://arxiv.org/pdf/1906.08931.pdf</a></td>
<td align="center">ACL2019</td>
<td></td>
</tr>
<tr>
<td align="center">Entity-Relation Extraction as Multi-turn Question Answering</td>
<td align="center">关系抽取</td>
<td align="center">多回合QA；上下文识别答案范围任务</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.05529.pdf">https://arxiv.org/pdf/1905.05529.pdf</a></td>
<td align="center">ACL2019</td>
<td></td>
</tr>
<tr>
<td align="center">Graph Neural Networks with Generated Parameters for Relation</td>
<td align="center">关系抽取</td>
<td align="center">图神经网络（GNN）；多跳关系推理</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1902.00756.pdf">https://arxiv.org/pdf/1902.00756.pdf</a></td>
<td align="center">ACL2019</td>
<td></td>
</tr>
<tr>
<td align="center">Kernelized Hashcode Representations for Biomedical Relation Extraction</td>
<td align="center">关系分类</td>
<td align="center">核化的局部敏感哈希（KLSH）；降低计算成本</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.04044.pdf">https://arxiv.org/pdf/1711.04044.pdf</a></td>
<td align="center">ACL2019</td>
<td></td>
</tr>
<tr>
<td align="center">Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs</td>
<td align="center">关系抽取</td>
<td align="center">图神经网络模型；文档级关系提取</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.00228v1.pdf">https://arxiv.org/pdf/1909.00228v1.pdf</a></td>
<td align="center">EMNLP2019</td>
<td></td>
</tr>
</tbody></table>
<h4 id="4-1-2-远监督方法"><a href="#4-1-2-远监督方法" class="headerlink" title="4.1.2. 远监督方法"></a>4.1.2. 远监督方法</h4><table>
<thead>
<tr>
<th align="center">论文题目</th>
<th align="center">抽取任务</th>
<th align="center">关键词</th>
<th align="center">论文链接</th>
<th align="center">会议及年份</th>
<th align="center">code</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Hybrid Attention-based Prototypical Networks for Noisy Few-Shot Relation Classification</td>
<td align="center">关系分类</td>
<td align="center">远监督；噪声；混合注意力圆形网络</td>
<td align="center"><a target="_blank" rel="noopener" href="https://gaotianyu1350.github.io/assets/aaai2019_hatt_paper.pdf">https://gaotianyu1350.github.io/assets/aaai2019_hatt_paper.pdf</a></td>
<td align="center">AAAI2019</td>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/thunlp/HATT-Proto">https://github.com/thunlp/HATT-Proto</a></td>
</tr>
<tr>
<td align="center">A Hierarchical Framework for Relation Extraction with Reinforcement Learning</td>
<td align="center">关系提取</td>
<td align="center">增强关系类型系和实体交互；分层强化学习（HRL）框架；远监督数据集</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.03925.pdf">https://arxiv.org/pdf/1811.03925.pdf</a></td>
<td align="center">AAAI2019</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Cross-relation Cross-bag Attention for Distantly-supervised Relation Extraction</td>
<td align="center">关系提取</td>
<td align="center">远监督抗噪；Cross-relation Cross-bag Selective Attention；多实例学习；句子级别；注意力机制；关注高质量实体对</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.10604.pdf">https://arxiv.org/pdf/1812.10604.pdf</a></td>
<td align="center">AAAI2019</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Structured Minimally Supervised Learning for Neural Relation Extraction</td>
<td align="center">关系提取</td>
<td align="center">最小监督；学习的表示形式；结构化学习</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.00118.pdf">https://arxiv.org/pdf/1904.00118.pdf</a></td>
<td align="center">NAACL2019</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Combining Distant and Direct Supervision for Neural Relation Extraction</td>
<td align="center">关系提取</td>
<td align="center">降噪；监督学习+远监督模型</td>
<td align="center"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1810.12956.pdf">https://arxiv.org/pdf/1810.12956.pdf</a></td>
<td align="center">NAACL2019</td>
<td align="center"><a target="_blank" rel="noopener" href="https://github.com/allenai/comb_dist_direct_relex/">https://github.com/allenai/comb_dist_direct_relex&#x2F;</a></td>
</tr>
<tr>
<td align="center">Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions</td>
<td align="center">关系提取</td>
<td align="center">句子级别的Attention；</td>
<td align="center"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N19-1288.pdf">https://www.aclweb.org/anthology/N19-1288.pdf</a></td>
<td align="center">NAACL2019</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">GAN Driven Semi-distant Supervision for Relation Extraction</td>
<td align="center">关系提取</td>
<td align="center">半远监督；生成对抗网络（GAN）</td>
<td align="center"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/N19-1307">https://www.aclweb.org/anthology/N19-1307</a></td>
<td align="center">NAACL 2019</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Improving Distantly-Supervised Relation Extraction with Joint Label Embedding</td>
<td align="center">关系提取</td>
<td align="center">多层注意力模型；联合标签嵌入</td>
<td align="center"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D19-1395.pdf">https://www.aclweb.org/anthology/D19-1395.pdf</a></td>
<td align="center">NAACL 2019</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction</td>
<td align="center">关系提取</td>
<td align="center">协作式学习；卷积神经网（CNN)；卷积运算内部自注意机制</td>
<td align="center"><a target="_blank" rel="noopener" href="https://www.aclweb.org/anthology/D19-1037.pdf">https://www.aclweb.org/anthology/D19-1037.pdf</a></td>
<td align="center">NAACL 2019</td>
<td align="center"></td>
</tr>
</tbody></table>
<h2 id="5-相关文献"><a href="#5-相关文献" class="headerlink" title="5. 相关文献"></a>5. 相关文献</h2><p><a target="_blank" rel="noopener" href="https://github.com/BDBC-KG-NLP/IE-Survey">收录文章</a></p>
<ul>
<li>[1] Automatic Acquisition of Hyponyms From Large Text Corpora.</li>
<li>[2] Combining Lexical, Syntactic, and Semantic Features with Maximum Entropy Models for Information Extraction.</li>
<li>[3] Extracting Relations with Integrated Information Using Kernel Methods</li>
<li>[4] Exploring Various Knowledge in Relation Extraction</li>
<li>[5] A Systematic Exploration of the Feature Space for Relation Extraction</li>
<li>[6] Kernel Methods for Relation Extraction</li>
<li>[7] Dependency Tree Kernels for Relation Extraction </li>
<li>[8] A Shortest Path Dependency Kernel for Relation Extraction</li>
<li>[9] A Composite Kernel to Extract Relations between Entities with Both Flat and Structured Features  </li>
<li>[10] Tree Kernel-Based Relation Extraction with Context-Sensitive Structured Parse Tree Information</li>
<li>[11] End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures. ACL 2016:1105–1116</li>
<li>[12] Katiyar, et al. Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees. ACL 2017: 917-928</li>
<li>[13] Zheng, et al. Joint extraction of entities and relations based on a novel tagging scheme. ACL 2017: 1227-1236</li>
<li>[14] Dai,et al. Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling. AAAI 2019: 6300-6308</li>
<li>[15] Zen, et al. Distant Supervision for Relation Extraction via Piecewise  Convolutional Neural Networks. EMNLP 2015: 1753-1762</li>
<li>[16] Lin ,et al. Neural Relation Extraction with Selective Attention over Instances.  ACL 2016:2124–2133</li>
<li>[17] Distant Supervision for Relation Extraction with Sentence-level Attention and Entity Descriptions</li>
<li>[18] Feng ,et al. Reinforcement Learning for Relation Classification from Noisy Data. AAAI 2018: 5779-5786</li>
<li>[19] Soared ,et al. Matching the Blanks: Distributional Similarity for Relation Learning. ACL  2019: 2895-2905</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96-%E5%AD%A6%E6%9C%AF%E7%95%8C/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-关系抽取调研-工业界" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/">关系抽取调研-工业界</a>
    </h1>
  

        
        <a href="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/" class="archive-article-date">
  	<time datetime="2021-10-30T12:04:36.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-10-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="关系抽取调研——工业界"><a href="#关系抽取调研——工业界" class="headerlink" title="关系抽取调研——工业界"></a>关系抽取调研——工业界</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><p><a href="#1-%E4%BB%BB%E5%8A%A1">1. 任务</a></p>
<ul>
<li><a href="#11-%E4%BB%BB%E5%8A%A1%E5%AE%9A%E4%B9%89">1.1. 任务定义</a></li>
<li><a href="#12-%E6%95%B0%E6%8D%AE%E9%9B%86">1.2. 数据集</a></li>
<li><a href="#13-%E8%AF%84%E6%B5%8B%E6%A0%87%E5%87%86">1.3. 评测标准</a></li>
</ul>
</li>
<li><p><a href="#2-%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93">2. 方法总结</a></p>
<ul>
<li><a href="#21-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E6%9D%BF%E7%9A%84%E6%96%B9%E6%B3%95">2.1. 基于模板的方法</a><ul>
<li><a href="#211-%E5%9F%BA%E4%BA%8E%E8%A7%A6%E5%8F%91%E8%AF%8D/%E5%AD%97%E7%AC%A6%E4%B8%B2">2.1.1. 基于触发词&#x2F;字符串</a></li>
<li><a href="#212-%E5%9F%BA%E4%BA%8E%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95">2.1.2. 基于依存句法</a></li>
</ul>
</li>
<li><a href="#22-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">2.2. 监督学习</a><ul>
<li><a href="#221-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">2.2.1. 机器学习</a></li>
<li><a href="#222-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0">2.2.2. 深度学习 Pipeline vs Joint Model</a></li>
</ul>
</li>
<li><a href="#23-%E5%8D%8A%E7%9B%91%E7%9D%A3/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%96%B9%E6%B3%95">2.3. 半监督&#x2F;无监督方法</a><ul>
<li><a href="#231-Bootstrapping">2.3.1. Bootstrapping</a></li>
<li><a href="#232-%E5%9F%BA%E4%BA%8E%E8%BF%9C%E7%A8%8B%E7%9B%91%E7%9D%A3%E7%9A%84%E6%96%B9%E6%B3%95">2.3.2. 基于远程监督的方法</a></li>
</ul>
</li>
</ul>
</li>
<li><p><a href="#3-%E6%8A%BD%E5%8F%96%E5%B7%A5%E5%85%B7%E5%BA%94%E7%94%A8">3. 抽取工具应用</a></p>
<ul>
<li><a href="#31-TextRunner">3.1. TextRunner</a></li>
<li><a href="#32-OLLIE">3.2. OLLIE：开放三元组知识抽取</a></li>
<li><a href="#33-IEPY">3.3. IEPY</a></li>
<li><a href="#34-spaCy">3.4. spaCy</a></li>
<li><a href="#35-NELL">3.5. NELL</a></li>
<li><a href="#36-Deepdive">3.6. Deepdive</a></li>
<li><a href="#37-Standford">3.7. Standford</a></li>
</ul>
</li>
<li><p><a href="#4-%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE">4.相关文献</a></p>
</li>
<li><p><a href="#5-%E5%8F%82%E8%80%83%E8%B5%84%E6%BA%90">5.参考资源</a></p>
</li>
</ul>
<h2 id="1-任务"><a href="#1-任务" class="headerlink" title="1. 任务"></a>1. 任务</h2><h3 id="1-1-任务定义"><a href="#1-1-任务定义" class="headerlink" title="1.1. 任务定义"></a>1.1. 任务定义</h3><p>自动识别句子中实体之间具有的某种语义关系。根据参与实体的多少可以分为二元关系抽取（两个实体）和多元关系抽取（三个及以上实体）。</p>
<p>通过关注两个实体间的语义关系，可以得到（arg1, relation, arg2）三元组，其中arg1和arg2表示两个实体，relation表示实体间的语义关系。</p>
<p>根据处理数据源的不同，关系抽取可以分为以下三种：</p>
<ul>
<li>面向结构化文本的关系抽取：包括表格文档、XML文档、数据库数据等。</li>
<li>面向非结构化文本的关系抽取：纯文本。</li>
<li>面向半结构化文本的关系抽取：介于结构化和非结构化之间。</li>
</ul>
<p>根据抽取文本的范围不同，关系抽取可以分为以下两种：</p>
<ul>
<li>句子级关系抽取：从一个句子中判别两个实体间是何种语义关系。</li>
<li>语料（篇章）级关系抽取：不限定两个目标实体所出现的上下文。</li>
</ul>
<p>根据所抽取领域的划分，关系抽取又可以分为以下两种：</p>
<ul>
<li>限定域关系抽取：在一个或者多个限定的领域内对实体间的语义关系进行抽取，限定关系的类别，可看成是一个文本分类任务。</li>
<li>开放域关系抽取：不限定关系的类别。</li>
</ul>
<p>限定域关系抽取方法：</p>
<ul>
<li>基于模板的关系抽取方法：通过人工编辑或者学习得到的模板对文本中的实体关系进行抽取和判别，受限于模板的质量和覆盖度，可扩张性不强。</li>
<li>基于机器学习的关系抽取方法：将关系抽取看成是一个分类问题。</li>
</ul>
<h3 id="1-2-常见数据集"><a href="#1-2-常见数据集" class="headerlink" title="1.2. 常见数据集"></a>1.2. 常见数据集</h3><h4 id="工业界数据集"><a href="#工业界数据集" class="headerlink" title="工业界数据集"></a>工业界数据集</h4><p>由于工业界的数据集通常来自其自身业务的记录，并不对外公开，故以下只举例介绍相关比赛中出现的数据集（下载链接因版权原因，随时删除）：</p>
<h5 id="2019全国知识图谱与语义计算大会"><a href="#2019全国知识图谱与语义计算大会" class="headerlink" title="2019全国知识图谱与语义计算大会"></a><a target="_blank" rel="noopener" href="https://conference.bj.bcebos.com/ccks2019/eval/webpage/index.html">2019全国知识图谱与语义计算大会</a></h5><p>​	<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1v5m5yIxIufmz5lXoDWcZ6A">数据集 提取码：ta8z</a></p>
<ul>
<li><p><strong>任务目标</strong></p>
<ul>
<li>在本次任务中，我们重点关注人物之间的关系抽取研究，简称IPRE（Inter-Personal Relationship Extraction）。给定一组人物实体对和包含该实体对的句子，找出给定实体对在已知关系表中的关系。我们将从以下两个方面进行评测：</li>
<li>Sent-Track:从句子级别上根据给定句子预测给定人物实体对的关系<ul>
<li>输入：一组人物实体对和包含该实体对的一个句子</li>
<li>输出：该人物实体对的关系</li>
<li>样例一：</li>
<li>输入：</li>
<li>贾玲\t冯巩\t贾玲，80后相声新秀，师承中国著名相声表演艺术家冯巩。</li>
<li>输出：</li>
<li>人物关系&#x2F;师生关系&#x2F;老师</li>
</ul>
</li>
<li>Bag-Track:从包级别上根据给定句子集合预测给定人物实体对的关系<ul>
<li>输入：一组人物实体对和包含该实体对的若干句子</li>
<li>输出：该人物实体对的关系</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>数据来源</strong></p>
<ul>
<li>主要来源于互联网网页文本，其中验证集和测试集是通过人工进行标注的，而训练集是通过远程监督（Distant Supervision）自动生成的。</li>
<li>总共有34类人物关系，包括一类特殊关系NA</li>
<li>本次竞赛使用的SKE数据集是业界规模最大的基于schema的中文信息抽取数据集，其包含超过43万三元组数据、21万中文句子及50个已定义好的schema，表1中展示了SKE数据集中包含的50个schema及对应的例子。数据集中的句子来自百度百科和百度信息流文本。数据集划分为17万训练集，2万验证集和2万测试集。其中训练集和验证集用于训练，可供自由下载，测试集分为两个，测试集1供参赛者在平台上自主验证，测试集2在比赛结束前一周发布，不能在平台上自主验证，并将作为最终的评测排名。</li>
</ul>
</li>
<li><p><strong>评价指标</strong>：</p>
<ul>
<li>精确率（Precision, P）、召回率（Recall, R）和F1值（F1-measure, F1），分为Sent-Track和Bag-Track的两个部分，每部分按F1值分别排名。只统计预测结果中非NA的数目。</li>
<li>F1最终结果越接近1分数越高。</li>
</ul>
</li>
<li><p><strong>解决方案</strong></p>
<ul>
<li>top1评测论文：<a target="_blank" rel="noopener" href="https://conference.bj.bcebos.com/ccks2019/eval/webpage/pdfs/eval_paper_3_2.pdf">https://conference.bj.bcebos.com/ccks2019/eval/webpage/pdfs/eval_paper_3_2.pdf</a></li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://lic2019.ccf.org.cn/kg">2019语言与智能技术竞赛</a></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/14Z94JLc6vkcVoYb3OBMG3A">数据集  提取码：dk4n</a></p>
</li>
<li><p><strong>任务目标</strong></p>
<ul>
<li>给定<em>schema</em>约束集合及句子<em>sent</em>，其中<em>schema</em>定义了关系<em>P</em>以及其对应的主体<em>S</em>和客体<em>O</em>的类别，例如<em>（S_TYPE:人物，P:妻子，O_TYPE:人物）、（S_TYPE:公司，P:创始人，O_TYPE:人物）</em>等。 任务要求参评系统自动地对句子进行分析，输出句子中所有满足<em>schema</em>约束的<em>SPO</em>三元组知识*Triples&#x3D;[(S1, P1, O1), (S2, P2, O2)…]*。</li>
<li><strong>输入&#x2F;输出:</strong></li>
<li><em>(1)</em> 输入:<em>schema</em>约束集合及句子<em>sent</em></li>
<li><em>(2)</em> 输出:句子<em>sent</em>中包含的符合给定<em>schema</em>约束的三元组知识<em>Triples</em></li>
</ul>
</li>
<li><p><strong>数据集说明</strong></p>
</li>
<li><p>使用的SKE数据集是业界规模最大的基于schema的中文信息抽取数据集，其包含超过43万三元组数据、21万中文句子及50个已定义好的schema，表1中展示了SKE数据集中包含的50个schema及对应的例子。数据集中的句子来自百度百科和百度信息流文本。数据集划分为17万训练集，2万验证集和2万测试集。其中训练集和验证集用于训练，可供自由下载，测试集分为两个，测试集1供参赛者在平台上自主验证，测试集2在比赛结束前一周发布，不能在平台上自主验证，并将作为最终的评测排名。</p>
</li>
<li><p>具体说明：<a target="_blank" rel="noopener" href="https://www.biendata.com/competition/chip2019/data/">https://www.biendata.com/competition/chip2019/data/</a></p>
</li>
<li><p><strong>评价指标</strong></p>
<ul>
<li>Precision、Recall、F1值</li>
</ul>
</li>
<li><p><strong>top1方案及结果</strong></p>
<ul>
<li>解决方案：<a target="_blank" rel="noopener" href="https://github.com/yuanxiaosc/Entity-Relation-Extraction/blob/master/Schema%E7%BA%A6%E6%9D%9F%E7%9A%84%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%EF%BC%88%22%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%22%E4%BB%BB%E5%8A%A1%E5%86%A0%E5%86%9B%E9%98%9F%E4%BC%8D%E6%8A%A5%E5%91%8A%EF%BC%89.pdf">Schema约束的知识抽取系统架构（“信息抽取”任务冠军队伍报告）</a></li>
<li>最高得分：89.3% F1 在测试集，投入使用效果 87.1% F1。</li>
<li>其他方案：<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/baidu/information-extraction">Baidu Official Baseline Model(Python2.7)</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/yuanxiaosc/information-extraction">Baseline Model(Python3)</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/yuanxiaosc/Multiple-Relations-Extraction-Only-Look-Once">Multiple-Relations-Extraction-Only-Look-Once</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/yuanxiaosc/Schema-based-Knowledge-Extraction">Schema-based-Knowledge-Extraction</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/competition/detail/31?isFromCcf=true">2020语言与智能技术竞赛</a></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1pK6MSA5fCqYs_Y_RpRmiCA">数据集 提取码：8ccx</a></p>
</li>
<li><p><strong>任务目标</strong>：</p>
<ul>
<li><p>在给定的文本句子中，根据预先定义的schema集合，抽取出所有满足 schema 约束的 SPO 三元组。schema 定义了关系 P 以及其对应的主体 S 和客体 O 的类别，根据 O 类型的复杂程度可以划分为以下两种：</p>
<ol>
<li><p><strong>简单 O 值</strong>：也就是说 O 是一个单一的文本。简单 O 值是最常见关系类型，去年竞赛中所发布的所有 schema 都属于这种类型。为了保持格式统一，简单 O 值类型的 schema 定义通过结构体保存，结构体中只有一个 @value 字段存放真正的 O 值类型。例如，「妻子」关系的 schema 定义为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    S_TYPE: 人物,</span><br><span class="line">    P: 妻子,</span><br><span class="line">    O_TYPE: &#123;</span><br><span class="line">        @value: 人物</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>复杂 O 值</strong>：也就是说 O 是一个结构体，由多个语义明确的文本共同组成，多个文本对应了结构体中的多个槽位（slot）。在复杂 O 值类型的定义中，@value 槽位可以认为是该关系的默认 O 值槽位，对于该关系不可或缺，其他槽位均可缺省。例如，「饰演」关系中 O 值有两个槽位 @value 和 inWork，分别表示「饰演的角色是什么」以及「在哪部影视作品中发生的饰演关系」，其 schema 定义为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    S_TYPE: 娱乐人物,</span><br><span class="line">    P: 饰演,</span><br><span class="line">    O_TYPE: &#123;</span><br><span class="line">        @value: 角色</span><br><span class="line">        inWork: 影视作品</span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p><strong>输入&#x2F;输出</strong>：</p>
<ul>
<li>输入：schema约束集合及句子sent</li>
<li>输出： 句子sent中包含的符合给定schema约束的三元组知识Triples</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>数据集说明</strong>：</p>
<ul>
<li>使用的DuIE2.0数据集是业界规模最大的基于schema的中文信息抽取数据集，其包含超过21万中文句子及48个已定义好的schema，<a target="_blank" rel="noopener" href="https://ai.baidu.com/file/18FAC5D981664C07B7314731229C214B">表1</a> 中展示了DuIE2.0数据集中包含的43个简单知识的schema及对应的例子，<a target="_blank" rel="noopener" href="https://ai.baidu.com/file/7660F27FA19E43D2AC6CF2CBD6A2D271">表2</a> 中展示了DuIE2.0数据集中包含的5个复杂知识的schema及对应的例子。数据集中的句子来自百度百科、百度贴吧和百度信息流文本。数据集划分为17万训练集，2万验证集和2万测试集。</li>
</ul>
</li>
<li><p><strong>评估方法</strong>：</p>
<ul>
<li>对测试集上给出的 SPO 结果和人工标注的 SPO 结果进行精准匹配，采用 Precision，Recall 和 F1 值作为评价指标。对于复杂 O 值类型的 SPO，必须所有槽位都精确匹配才认为该 SPO 抽取正确。</li>
</ul>
</li>
<li><p><strong>基线系统 Baseline Systems</strong></p>
<ul>
<li>GitHub 基线系统<br><a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Research/tree/master/KG/DuIE_Baseline">https://github.com/PaddlePaddle/Research/tree/master/KG/DuIE_Baseline</a></li>
<li>百度AI Studio 基线系统示例<br><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/357344">https://aistudio.baidu.com/aistudio/projectdetail/357344</a></li>
</ul>
</li>
</ul>
<h3 id="1-3-评测标准"><a href="#1-3-评测标准" class="headerlink" title="1.3. 评测标准"></a>1.3. 评测标准</h3><ul>
<li><p>P:  准确率</p>
</li>
<li><p>R：召回率</p>
</li>
<li><p>F1:  2 P*R&#x2F;(P+R)</p>
</li>
</ul>
<h2 id="2-方法总结"><a href="#2-方法总结" class="headerlink" title="2. 方法总结"></a>2. 方法总结</h2><h3 id="2-1-基于模板的方法"><a href="#2-1-基于模板的方法" class="headerlink" title="2.1. 基于模板的方法"></a>2.1. 基于模板的方法</h3><p><strong>模板匹配</strong>：是关系分类中最常见的方法，使用一个模板库对输入文本两个给定实体进行上下文匹配，如果满足模板对应关系，则作为实体对之间的关系。常见的模板匹配方法主要包括：</p>
<ul>
<li><strong>人工模板</strong>：主要用于判断实体间是否存在上下位关系。上下位关系的自然语言表达方式相对有限，采用人工模板就可以很好完成关系分类。但对于自然语言表达形式非常多的关系类型而言，这就需要采取统计模板。</li>
<li><strong>统计模板</strong>：无须人工构建，主要基于搜索引擎进行统计模板抽取。具体地，将已知实体对作为查询语句，抓取搜索引擎返回的前n个结果文档并保留包含该实体对的句子集合，寻找包含实体对的最长字串作为统计模板，保留置信度较高的模板用于关系分类。</li>
</ul>
<h4 id="2-1-1-基于触发词-字符串"><a href="#2-1-1-基于触发词-字符串" class="headerlink" title="2.1.1. 基于触发词&#x2F;字符串"></a>2.1.1. 基于触发词&#x2F;字符串</h4><p>例：句子中上下位关系，比如hyponym(China; Asia countries)。从下面两个句子中都可以抽取出这种关系：</p>
<p>Asia countries, especially China, Japan, and India…</p>
<p>Asia countries, such as China, Japan, and India…</p>
<p>两个实体之间的especially和such as可以看做这种关系的特征。寻找更多表达这种关系的句子，构造规则模板，即可用于抽取构成上下位关系的实体，从而发现新的三元组。</p>
<h4 id="2-1-2-基于依存句法"><a href="#2-1-2-基于依存句法" class="headerlink" title="2.1.2. 基于依存句法"></a>2.1.2. 基于依存句法</h4><p>使用NLP工具获取句子相关特征，对处理结果一般进行如下处理：</p>
<ol>
<li>对输入句子进行分词、词性标注、命名实体识别、依存分析等处理</li>
<li>根据句子依存句法树结构进行规则匹配，每匹配一条规则就生成一个三元组</li>
<li>根据扩展规则对抽取到的三元组进行扩展</li>
<li>对三元组实体和触发词进一步处理抽取出关系</li>
</ol>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>手写规则的 <strong>优点</strong> ：</p>
<ul>
<li>人工规则有高准确率(high-precision)</li>
<li>可以为特定领域定制(tailor)</li>
<li>在小规模数据集上容易实现，构建简单</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>低召回率(low-recall)</li>
<li>特定领域的模板需要专家构建，要考虑周全所有可能的 pattern 很难，也很费时间精力</li>
<li>需要为每条关系来定义 pattern</li>
<li>难以维护</li>
<li>可移植性差</li>
</ul>
<h3 id="2-2-监督学习"><a href="#2-2-监督学习" class="headerlink" title="2.2. 监督学习"></a>2.2. 监督学习</h3><p>有监督的关系抽取方法：</p>
<ul>
<li>基于特征工程的方法：需要显示地将关系实例转换成分类器可以接受的特征向量</li>
<li>基于核函数的方法：直接以结构树为处理对象，在计算关系之间距离的时候不再使用特征向量的内积而是用核函数</li>
<li>基于神经网络的方法：直接从输入的文本中自动学习有效的特征表示，是一个端到端的过程</li>
</ul>
<h4 id="2-2-1-机器学习"><a href="#2-2-1-机器学习" class="headerlink" title="2.2.1. 机器学习"></a>2.2.1. 机器学习</h4><p>将关系抽取看成是一个基于构造特征的分类问题</p>
<p><strong>常见特征</strong>：</p>
<ul>
<li><p>实体特征，包括实体前后的词，实体类型，实体之间的距离等</p>
</li>
<li><p>chunk，如 NP，VP，PP 这类短语</p>
</li>
<li><p>实体间的依存关系，实体间树结构的距离，及其他特定的结构信息</p>
</li>
</ul>
<p><strong>标准流程</strong>：</p>
<ul>
<li>预先定义提取的关系集合</li>
<li>选择相关命名实体集合</li>
<li>寻找并标注数据</li>
<li>选择有代表性的语料库</li>
<li>标记命名实体</li>
<li>人工标注实体间关系</li>
<li>分割训练、开发、测试集</li>
<li>设计特征</li>
<li>选择并训练分类器</li>
<li>评估结果</li>
</ul>
<p>通常会训练两个分类器，第一个分类器是 yes&#x2F;no 的二分类，判断命名实体间是否有关系，如果有关系，再送到第二个分类器，给实体分配关系类别。这样做的好处是通过排除大多数的实体对来加快分类器的训练过程，另一方面，对每个任务可以使用基于具体任务的特征集。常用的分类器包括 <strong>MaxEnt、Naive Bayes、SVM</strong> 等。</p>
<h4 id="2-2-2-深度学习-Pipeline-vs-Joint-Model"><a href="#2-2-2-深度学习-Pipeline-vs-Joint-Model" class="headerlink" title="2.2.2. 深度学习 Pipeline vs Joint Model"></a>2.2.2. 深度学习 Pipeline vs Joint Model</h4><p><strong>Pipeline</strong></p>
<p>Pipeline方法先在句子中抽取实体、而后再抽取关系。即把实体识别和关系分类作为两个完全独立的过程，互不影响，关系的识别依赖于实体识别的效果。</p>
<p><strong>Joint Model</strong></p>
<p>现有联合抽取模型总体上有两大类：</p>
<p>1、<strong>共享参数</strong>的联合抽取模型</p>
<p>通过共享参数（共享输入特征或者内部隐层状态）实现联合，此种方法对子模型没有限制，但是由于使用独立的解码算法，导致实体模型和关系模型之间交互不强。</p>
<p>2、<strong>联合解码</strong>的联合抽取模型</p>
<p>为了加强实体模型和关系模型的交互，复杂的联合解码算法被提出来，比如整数线性规划等。这种情况下<strong>需要对子模型特征的丰富性以及联合解码的精确性之间做权衡</strong>：</p>
<ul>
<li>一方面如果设计精确的联合解码算法，往往需要对特征进行限制，例如用条件随机场建模，使用维特比解码算法可以得到全局最优解，但是往往需要限制特征的阶数。</li>
<li>另一方面如果使用近似解码算法，比如集束搜索，在特征方面可以抽取任意阶的特征，但是解码得到的结果是不精确的。</li>
</ul>
<p>因此，需要一个算法可以在不影响子模型特征丰富性的条件下加强子模型之间的交互。</p>
<p>此外，很多方法再进行实体抽取时并没有直接用到关系的信息，然而这种信息是很重要的。需要一个方法可以<strong>同时考虑一个句子中所有实体、实体与关系、关系与关系之间的交互</strong>。</p>
<p><strong>Pipeline对比 Joint Model</strong>：</p>
<p>相比于传统的Pipeline方法，联合抽取能获得更好的性能。虽然Pipeline方法易于实现，这两个抽取模型的灵活性高，实体模型和关系模型可以使用独立的数据集，并不需要同时标注实体和关系的数据集。但存在以下缺点：</p>
<ol>
<li>误差积累：实体抽取的错误会影响下一步关系抽取的性能。</li>
<li>实体冗余：由于先对抽取的实体进行两两配对，然后再进行关系分类，没有关系的候选实体对所带来的冗余信息，会提升错误率、增加计算复杂度。</li>
<li>交互缺失：忽略了这两个任务之间的内在联系和依赖关系。</li>
</ol>
<h3 id="2-3-半监督-无监督方法"><a href="#2-3-半监督-无监督方法" class="headerlink" title="2.3. 半监督&#x2F;无监督方法"></a>2.3. 半监督&#x2F;无监督方法</h3><h4 id="2-3-1-Bootstrapping"><a href="#2-3-1-Bootstrapping" class="headerlink" title="2.3.1.  Bootstrapping"></a>2.3.1.  Bootstrapping</h4><p><strong>Bootstrapping</strong>：利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中并不断迭代。Bootstrapping的优点构建成本低，适合大规模的关系任务并且具备发现新关系的能力，但也存在对初始种子较为敏感、存在语义漂移、准确率等问题。Bootstrapping 如今在工业界中依旧是快速构建大规模知识图谱的重要方法。在实际使用中，可以考虑结合基于深度语义模型的关系抽取方法，进一步提高图谱召回。</p>
<p><strong>工业应用</strong>：</p>
<p>bootstrapping比较常见的方法有<strong>DIPRE</strong>和<strong>Snowball</strong>。和<strong>DIPRE</strong>相比，<strong>Snowball</strong>通过对获得的模板pattern进行置信度计算，一定程度上可以保证抽取结果质量。</p>
<p><strong>DIPRE: Dual Iterative Pattern Expansion</strong></p>
<p>DIPRE是从HTML文档集合中提取结构化关系（或表格）的一种方法。 该方法在类似Web的环境下效果最好，其中的表格要提取的tuples往往会在反复出现在集合文档中一致的context内。 DIPRE利用这种集合冗余和内在的结构以提取目标关系并简化训练。</p>
<p><strong>DIPRE Pipeline</strong></p>
<p>DIPRE pattern由5-tuple <em>&lt;order, urlprefix, left, middle, right&gt;<em>组成，并通过将具有相等字符串分隔实体（</em>middle</em>）的共现种子tuples group在一起生成，然后将 <em>left</em> 字符串和 <em>right</em> 字符串分别设置为实体左侧和右侧上下文的最长公共子字符串。 <em>order</em> 反映了实体出现的顺序，<em>urlprefix</em> 设置为发现了 tuples 的源URL的最长公共子串。在从最初的种子 tuples 中生成一些 pattern 之后，DIPRE扫描包含 pattern 可匹配的文本片段的可用文档。随后，DIPRE生成新的tuples，并将它们用作新的“种子”。DIPRE反复迭代以上过程找到文档中的新 tuples 以识别新的可靠 patterns。</p>
<p>伪代码：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">收集具有关系R的一组种子tuples</span><br><span class="line"></span><br><span class="line">迭代： </span><br><span class="line">1.找到包含这些种子tuples的句子 </span><br><span class="line">2.查看种子tuples之间或周围的上下文，并泛化该上下文以生成patterns</span><br><span class="line">3.用这些patterns找到更多种子tuples</span><br></pre></td></tr></table></figure>

<p><strong>DIPRE样例</strong></p>
<!-- ![img](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/dipre_demo.png) -->

<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/dipre_demo.png" class="" title="img">

<p>从 5 个种子 tuples 开始，找到包含种子的实例，替换关键词，形成 pattern，迭代匹配，就为 (author,book) 抽取到了 relation pattern，<em><strong>x, by y</strong></em>, 和 <em><strong>x, one of y’s</strong></em>。</p>
<p><strong>DIPRE利弊</strong></p>
<p><strong>优点：</strong></p>
<ol>
<li>能够从非结构化文本中抽取出结构化的关系</li>
<li>训练成本低，每个新场景只需要少量种子tuples。</li>
</ol>
<p><strong>缺点：</strong></p>
<ol>
<li>依赖 HTML 标签</li>
<li>缺少对新 pattern 和 tuples 的评估</li>
<li>抽取结果噪声较多</li>
<li>抽取结果 Recall 较低</li>
</ol>
<h4 id="2-3-2-基于远程监督的方法"><a href="#2-3-2-基于远程监督的方法" class="headerlink" title="2.3.2.  基于远程监督的方法"></a>2.3.2.  基于远程监督的方法</h4><p>远程监督算法基于一个非常重要的假设：<strong>对于一个已有的知识图谱中的一个三元组（由一对实体和一个关系构成），外部文档库中任何包含这对实体的句子，在一定程度上都反映了这种关系。</strong>基于这个假设，远程监督算法可以基于一个标注好的小型知识图谱，给外部文档库中的句子标注关系标签，相当于做了样本的自动标注，因此是一种半监督的算法。</p>
<p><strong>（1）多示例学习</strong>：主要基于Bag的特征进行关系分类，主要代表文献包括PCNN[1]、Selective Attention over Instances[2]、Multi-label CNNs[3]、APCNNs[4]，其中Bag的表示主要方式和池化方式为：</p>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/d363bf0e22b90c0aa36841a715d1074363b64e65/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d39393633303831346162626437363862653564363132333665656464316131365f31343430772e706e67"><img src="https://camo.githubusercontent.com/d363bf0e22b90c0aa36841a715d1074363b64e65/68747470733a2f2f706963332e7a68696d672e636f6d2f38302f76322d39393633303831346162626437363862653564363132333665656464316131365f31343430772e706e67" alt="img"></a></p>
<p><strong>（2）强化学习</strong>：在采用多示例学习策略时，可能会出现整个Bag包含大量噪声的情况。基于强化学习的CNN+RL[5]比句子级别和Bag级别的关系分类模型取得更好效果。</p>
<p>模型主要由样例选择器和关系分类器构成。样例选择器负责从样例中选择高质量的句子，采取强化学习方式在考虑当前句子的选择状态下选择样例；关系分类器向样例选择器反馈，改进选择策略。</p>
<!-- [![img](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/CNN%2BRL.png) -->



<p><strong>（3）预训练机制</strong>：采取“Matching the Blank[6]”方法，首次在预训练过程中引入关系分类目标，但仍然是自监督的，没有引入知识库和额外的人工标注，将实体metion替换为「BLANK」标识符。</p>
<ul>
<li>该方法认为包含相同实体对的句子对为正样本，而实体对不一样的句子对为负样本。如图，rA和rB构成正样本，rA和rC构成rB和rC构负样本。</li>
<li>不同于传统的远程监督，该方法训练中不使用关系标签，采用二元分类器对句子对进行相似度计算。预训练的损失包含2部分：MLM loss 和 二元交叉熵关系损失。</li>
<li>在FewRel数据集上，不进行任何tuning就已经超过了有监督的结果。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://camo.githubusercontent.com/29dfe763b28ca39cd2878098025c5ae4b376b601/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d39383831393332666538623737613939623066663536376139353835303035305f31343430772e706e67"><img src="https://camo.githubusercontent.com/29dfe763b28ca39cd2878098025c5ae4b376b601/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d39383831393332666538623737613939623066663536376139353835303035305f31343430772e706e67" alt="img"></a></p>
<h2 id="3-抽取工具应用"><a href="#3-抽取工具应用" class="headerlink" title="3. 抽取工具应用"></a>3. 抽取工具应用</h2><h3 id="3-1-TextRunner"><a href="#3-1-TextRunner" class="headerlink" title="3.1. TextRunner"></a>3.1. TextRunner</h3><p><strong>TEXTRUNNER</strong>三个关键步骤：</p>
<p>Open Information Extraction from the Web(TextRunner, 2007，华盛顿大学)</p>
<ul>
<li><strong>Self-Supervised Learner</strong>：构造训练数据集，学习一个贝叶斯分类器，判断(e*i, relation words, e_*j)是否是可信的关系</li>
<li><strong>Single-Pass Extractor</strong>：输入一句话，产生所有可能的候选三元组，使用分类器判别，保留可信的三元组</li>
<li><strong>Redundancy-Based Assessor</strong>：统计(e_*i, relation words, e_*j)发生在不同句子中的频次，保留高频词的结果作为最终结果</li>
</ul>
<p><strong>Self-Supervised Learner</strong>:</p>
<ul>
<li><p><strong>parsing</strong> :在一个小的数据集进行<strong>语法解析</strong>，解析句子中的名词短语</p>
</li>
<li><p><strong>构造三元组</strong>：将名词短语作为可能的实体e_i，两个名词短语之间的词语作为关系，构成三元组候选集合</p>
</li>
<li><p><strong>使用约束构造正负样本</strong>： 满足下述三个条件的作为正样本</p>
</li>
<li><ul>
<li>e<em>i e_j存在依赖路径，并且路径长度小于一定的值</em></li>
<li>The path from ei to ej along the syntax tree does not cross a sentence-like boundary (e.g. relative clauses)</li>
<li>e<em>i e</em>j都不是代词</li>
</ul>
</li>
<li><p><strong>训练分类器</strong>：三元组 <img src="https://www.zhihu.com/equation?tex=(e_i,+r_%7Bi,j%7D,+e_j)" alt="[公式]"> ,将三元组特征化，训练一个贝叶斯分类器；特征有</p>
</li>
<li><ul>
<li>presence of part-of-speech tag sequences in the relation <img src="https://www.zhihu.com/equation?tex=r_%7Bi,j%7D" alt="[公式]"></li>
<li>the number of tokens in <img src="https://www.zhihu.com/equation?tex=r_%7Bi,j%7D" alt="[公式]"></li>
<li>the number of stopwords in <img src="https://www.zhihu.com/equation?tex=r_%7Bi,j%7D" alt="[公式]"></li>
<li>whether or not an object e is found to be a proper noun</li>
<li>the part-of-speech tag to the left of ei</li>
<li>the part-of-speech tag to the right of ej .</li>
</ul>
</li>
</ul>
<p><strong>Single-Pass Extractor</strong>:</p>
<p>输入一个句子，处理过程如下</p>
<ul>
<li><strong>先进行词性标注</strong>，然后使用lightweight noun phrase chunker识别名词短语</li>
<li>识别<strong>名词短语之间的词语</strong>作为关系表示</li>
<li>使用分类器进行分类，判别这个三元组候选是否可信</li>
</ul>
<p><strong>Redundancy-based Assessor</strong>：</p>
<ul>
<li>会通过启发式的规则归一化关系短语，比如去除不必要的修饰词语</li>
<li>统计三元组的频数，如果这个三元组是从k个不同的句子中抽取得到的话</li>
</ul>
<h3 id="3-2-OLLIE"><a href="#3-2-OLLIE" class="headerlink" title="3.2. OLLIE"></a>3.2. OLLIE</h3><p>OLLIE支持基于语法依赖树的关系抽取。流程图如下，主要包含三个步骤</p>
<ul>
<li><strong>Constructing a Bootstrapping Set</strong>：使用REVERB已经抽取到的高质量的三元组作为Seed Tuples，使用Seed Tuple抽取包含这些seed tuple的句子，构造一个比较大的训练数据集</li>
<li><strong>Open Pattern Learning</strong>：基于语法解析，使用训练数据集学习open pattern templates&#x2F;抽取模式模板</li>
<li><strong>Pattern Matching for Extraction</strong>：使用学习到的open pattern templates来抽取新的三元组</li>
</ul>
<!-- ![img](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/OOLLIE.png) -->

<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/OOLLIE.png" class="" title="img">

<h3 id="3-3-IEPY"><a href="#3-3-IEPY" class="headerlink" title="3.3. IEPY"></a>3.3. IEPY</h3><p>开源项目：<a target="_blank" rel="noopener" href="https://github.com/machinalis/iepy">https://github.com/machinalis/iepy</a></p>
<p>主要做关系抽取：IEPY is an open source tool for Information Extraction focused on Relation Extraction. </p>
<p><strong>工具特征</strong>：</p>
<ol>
<li><p>带web-UI的语料标注⼯具。</p>
</li>
<li><p>基于主动学习的关系抽取的工具。</p>
</li>
<li><p>基于规则的关系抽取工具。</p>
</li>
<li><p>有web-UI帮助使用：</p>
<p> 1)方便非专业用户使用部分功能。</p>
<p> 2)允许分布式的用户输入。</p>
</li>
<li><p>通过斯坦福CoreNLP做共指解析。</p>
</li>
<li><p>可以基于开源代码作二次开发。</p>
</li>
</ol>
<h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p><strong>安装</strong>：</p>
<p>作为Python包安装，pip install iepy, 并下载第三方数据 iepy –download-third-party-data </p>
<p>使⽤：</p>
<p><strong>1</strong> 创建项目</p>
<p>iepy –create <project_name> </p>
<p><strong>2</strong> 导⼊要抽取的语料</p>
<p>python bin&#x2F;csv_to_iepy.py data.csv </p>
<p><strong>3</strong> 数据预处理（ text tokenization, sentence splitting, lemmatization, part-of-speech tagging, and named entity recognition）</p>
<p>python bin&#x2F;preprocess.py </p>
<p><strong>4</strong> 启动<strong>web-ui</strong>查看项⽬</p>
<p>python bin&#x2F;manage.py runserver </p>
<p><strong>5</strong> 进行<strong>active learning</strong>(需要自己再依据工具提示标一些数据)或<strong>rule-based</strong>(写规则)关系抽取</p>
<p><strong>6</strong> 在界面上标⼀些测试集来验证抽取效果。</p>
<!-- ![image-20200917104922545](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/NELL.png) -->
<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/NELL.png" class="" title="img">

<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><strong>功能</strong>：</p>
<p>对于要处理的语料导⼊到项目里，提供前面的预处理和两种方式的关系抽取。Active Learning的需要自己定义关系和标⼀些数据。Rule-based的需要自己写规则。也封装好了⼀些脚本⽅便的做导⼊数据、预处理、规则检查等。</p>
<p><strong>使用方式</strong>：</p>
<p>python包 + webUI，类似pyspider。可以用界面来定义关系和查看抽取结果、标注测试集等。不过还是需要⽤命令行来load数据，预处理等，这部分其实也可以在界面实现。</p>
<p><strong>评价</strong>：</p>
<p>由于开发的时间早，抽取的方法不新，也没有预先在⼤数据集上训练得到通用领域关系抽取的模型，需要用户自己定义关系并标注数据。每⼀个抽取任务创建⼀个project，使⽤web界面方便操作和可视化，感觉我们做领域迁移也可以采用这种⽅法，把流程固定，然后通过创建不同的project，导⼊不同的数据，定义不同的关系，然后⽤webUI进⾏可视化和人工操作。</p>
<h3 id="3-4-spaCy"><a href="#3-4-spaCy" class="headerlink" title="3.4. spaCy"></a>3.4. spaCy</h3><p><strong>3.4.1</strong> 介绍</p>
<p>工业级的NLP工具：功能很强⼤，不⽌是做Information Extraction，⽤Cython优化，各种处理超级快（官网fastest in the world），能⽤于在真实场景和产品里的。适合对用于Deep Learning的⽂本进行预处理。能和TensorFlow, PyTorch, scikit-learn, Gensim 等深度学习框架无缝衔接。</p>
<p><strong>3.4.2 工具特点</strong>：</p>
<ul>
<li>无损的tokenization </li>
<li>命名实体识别</li>
<li>⽀持53+语言</li>
<li>支持11种语言上的17个统计模型</li>
<li>预训练好的词向量</li>
<li>SOTA的速度</li>
<li>方便与深度学习集成</li>
<li>POS标注</li>
<li>带标记的依存句法分析</li>
<li>句法驱动的句子分割</li>
<li>内置用于语法和NER的可视化工具</li>
<li>方便的字符串-&gt;哈希值映射</li>
<li>导出到numpy数组</li>
<li>高效的⼆进制序列化</li>
<li>方便的模型打包和部署</li>
<li>稳健，经过严格评估的准确性</li>
</ul>
<h4 id="3-4-3-总结"><a href="#3-4-3-总结" class="headerlink" title="3.4.3 总结"></a>3.4.3 总结</h4><p>并非专门做信息抽取，也没有抽取关系的功能。封装了NLP相关的基础工作，并优化了速度以用于真实产品。</p>
<p>同时也允许用户自己训练模型load后使⽤。</p>
<p>使用方式：</p>
<p>python包+load下载的模型。</p>
<p><strong>评价</strong>：</p>
<p>功能很多很实用，定位在于做深度学习前面的文本预处理，且优化速度。使用方式和很多⼯具⼀样，使用python包，封装好各种通用功能和接口，再通过加载不同的模型实现使⽤在不同领域、语言或者应对方法改进的情况。</p>
<h3 id="3-5-NELL"><a href="#3-5-NELL" class="headerlink" title="3.5 NELL"></a>3.5 NELL</h3><p><strong>3.5.1</strong> 介绍</p>
<p>永恒语⾔学习：</p>
<p>Never-ending Language Learning。不断学习语⾔知识，2010年提出。</p>
<p><strong>architecture</strong>：</p>
<!-- ![image-20200917110152465](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/NELL_ARC.png) -->
<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/NELL_ARC.png" class="" title="img">

<!-- ![image-20200917111521876](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/NELL_PRO.png) -->
<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/NELL_PRO.png" class="" title="img">



<p><strong>流程</strong>：</p>
<p>利⽤少量标记样本集合训练学习模型, 然后⽤该模型去标记更多样本。（需要偶尔人工标注）。运⽤多视角学习(multi-view learning)分别从文本背景信息、网页结构信息、构词法特征以及规则学习4个角度进行新知识抽取和知识库的扩充。</p>
<p><strong>3.5.2 总结</strong></p>
<p>评价：</p>
<p>可以借鉴这种方式扩充构建好的知识库，对于通用领域知识库可以在网页文本上抽取，特定领域的可以喂相关领域的文档或者爬取到的网页文本。信息抽取工具应该不包含这个功能，而是通过这个⼯具的使用能够实现这种功能。</p>
<h3 id="3-6-Deepdive"><a href="#3-6-Deepdive" class="headerlink" title="3.6 Deepdive"></a>3.6 Deepdive</h3><p>官网地址：<a target="_blank" rel="noopener" href="http://deepdive.stanford.edu/">http://deepdive.stanford.edu/</a></p>
<p><a target="_blank" rel="noopener" href="http://deepdive.stanford.edu/">Deepdive</a>是stanford大学InfoLab实验室开发的一个开源知识抽取系统，它通过弱监督学习，从非结构化的文本中提取结构化的关系数据。DeepDive用于提取实体之间的复杂关系并推断涉及这些实体的事实。在使用Deepdive进行关系抽取的时候，使用者不需要关心算法，只需要指定实体的特征，Deepdive通过联合推理，即可得出两个实体之间有关系的概率。</p>
<p>Deepdive的优点如下：<br>（1）可以处理带噪声的数据，用户可以通过对断言设置置信度来矫正噪声<br>（2）可以通过使用已有的领域知识来指导推理结果，通过用户反馈的结果来提高预测的准确率<br>（3）使用远监督技术，不需要或仅需要少量数据即可完成抽取</p>
<p>抽取流程如下：</p>
<!-- ![image](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/deepdive.jpg) -->
<img src="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/deepdive.jpg" class="" title="img">


<p>一个中文抽取示例：股权抽取 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/43143663">https://zhuanlan.zhihu.com/p/43143663</a></p>
<h3 id="3-7-Stanford"><a href="#3-7-Stanford" class="headerlink" title="3.7 Stanford"></a>3.7 Stanford</h3><p>官网地址：<a target="_blank" rel="noopener" href="https://stanfordnlp.github.io/CoreNLP/">https://stanfordnlp.github.io/CoreNLP</a></p>
<p>Stanford CoreNLP是斯坦福大学提供的自然语言处理工具，是由Java写成的，可通过使用Web服务与CoreNLP进行交互，从而使用python等其他语言进行编程，目前提供python接口可直接安装使用，支持多种语言。</p>
<p>Open IE（开放信息提取）是指从纯文本中提取关系元组，与其他提取不同的是，Open IE 不需要提前定义schema，主要利用语言结构进行开放领域信息抽取。Stanford Open IE是Stanford CoreNLP包中的一个开放领域信息抽取模块，该模块的抽取思路如下：</p>
<p>1、先将句子分成几个子句（学习一个分类器）</p>
<p>2、最大程度地缩短每个子句，产生一组所需的句子片段</p>
<p>3、从片段中提取三元组（自然逻辑）</p>
<p>相关论文链接：<a target="_blank" rel="noopener" href="https://nlp.stanford.edu/pubs/2015angeli-openie.pdf">https://nlp.stanford.edu/pubs/2015angeli-openie.pdf</a></p>
<p>Relation Extractor（关系抽取）是Stanford CoreNLP中的另一个处理模块，用于抽取特定领域的关系。目前支持Live_In, Located_In, OrgBased_In, Work_For, and None这几种关系。用户可以使用提供的接口使用自己的数据集训练自己的模型，从而实现特定领域的关系抽取。该模块的抽取思路如下：</p>
<p>1、数据预处理：tokenization，part of speech tagging</p>
<p>2、实体识别（标注）</p>
<p>3、使用多类逻辑回归分类器对关系进行分类</p>
<p>Stanford Open IE&amp; Relation Extractor对比</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>领域</th>
<th>使用方法</th>
<th>用户使用</th>
</tr>
</thead>
<tbody><tr>
<td>Open IE</td>
<td>开放领域</td>
<td>下载StandfordCoreNLP包</td>
<td>可以使用java或者其他语言进行服务器与来进行编码</td>
</tr>
<tr>
<td>Relation Extractor</td>
<td>特定领域</td>
<td>下载StandfordCoreNLP包，用户可自行训练特定领域的模型</td>
<td>可以使用java或者其他语言与服务器交互来进行编码</td>
</tr>
</tbody></table>
<h2 id="4-相关文献"><a href="#4-相关文献" class="headerlink" title="4. 相关文献"></a>4. 相关文献</h2><ol>
<li>Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks. EMNLP</li>
<li>Attention over Instances (Lin 2016)</li>
<li>Relation Extraction with Multi-instance Multi-label Convolutional Neural Networks.</li>
<li>Distant Supervision for Relation Extraction with Sentence-Level Attention and Entity Descriptions</li>
<li>Reinforcement Learning for Relation Classification from Noisy Data</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.03158.pdf">Matching the Blanks: Distributional Similarity for Relation Learning</a></li>
<li>Riedel, Sebastian, Limin Yao, and Andrew McCallum. “Modeling relations and their mentions without labeled text.”<em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>. Springer, Berlin, Heidelberg, 2010.</li>
</ol>
<h2 id="5-参考资源"><a href="#5-参考资源" class="headerlink" title="5. 参考资源"></a>5. 参考资源</h2><p><a target="_blank" rel="noopener" href="https://github.com/BDBC-KG-NLP/IE-Survey">收录文章</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/139485679">https://zhuanlan.zhihu.com/p/139485679</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/77868938">https://zhuanlan.zhihu.com/p/77868938</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/189831468">SemEval-2020自由文本关系抽取冠军方案解读</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/WindChimeRan/NREPapers2019">https://github.com/WindChimeRan/NREPapers2019</a></p>
<p><a target="_blank" rel="noopener" href="https://paperswithcode.com/sota">https://paperswithcode.com/sota</a></p>
<p><a target="_blank" rel="noopener" href="http://www.ccks2019.cn/">2019全国知识图谱与语义计算大会</a></p>
<p><a target="_blank" rel="noopener" href="https://yuanxiaosc.github.io/categories/%E8%AE%BA%E6%96%87/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/">望江人工智库 信息抽取</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/yuanxiaosc/Entity-Relation-Extraction">https://github.com/yuanxiaosc/Entity-Relation-Extraction</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/145812779">https://zhuanlan.zhihu.com/p/145812779</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/10/30/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%E8%B0%83%E7%A0%94-%E5%B7%A5%E4%B8%9A%E7%95%8C/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-bert和xlnet" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/28/bert%E5%92%8Cxlnet/">bert和xlnet</a>
    </h1>
  

        
        <a href="/2021/10/28/bert%E5%92%8Cxlnet/" class="archive-article-date">
  	<time datetime="2021-10-28T01:35:10.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2021-10-28</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-AR与AE语言模型"><a href="#1-AR与AE语言模型" class="headerlink" title="1. AR与AE语言模型"></a>1. AR与AE语言模型</h2><p>AR: Autoregressive Language modeling<br>AE: AutoEncoding Language modeling</p>
<img src="/2021/10/28/bert%E5%92%8Cxlnet/3.awebp" class="" title="ARAE">

<p>AR语言模型：指的是，依据前面（或后面）出现的tokens来预测当前时刻的token，代表有ELMO,GPT等。<br>AE语言模型：通过上下文信息来预测被mask的token，代表有 BERT , Word2Vec(CBOW)  。</p>
<h3 id="二者有着它们各自的优缺点："><a href="#二者有着它们各自的优缺点：" class="headerlink" title="二者有着它们各自的优缺点："></a>二者有着它们各自的优缺点：</h3><h4 id="AR-语言模型："><a href="#AR-语言模型：" class="headerlink" title="AR 语言模型："></a>AR 语言模型：</h4><p>缺点： 它只能利用单向语义而不能同时利用上下文信息。ELMO 通过双向都做AR 模型，然后进行拼接，但从结果来看，效果并不是太好。<br>优点： 对生成模型友好，天然符合生成式任务的生成过程。这也是为什么 GPT 能够编故事的原因。</p>
<h4 id="AE-语言模型："><a href="#AE-语言模型：" class="headerlink" title="AE 语言模型："></a>AE 语言模型：</h4><p>缺点： 由于训练中采用了 [MASK] 标记，导致预训练与微调阶段不一致的问题。BERT独立性假设问题，即没有对被遮掩（Mask）的 token 之间的关系进行学习。此外对于生成式问题， AE 模型也显得捉襟见肘。<br>优点： 能够很好的编码上下文语义信息（即考虑句子的双向信息）， 在自然语言理解相关的下游任务上表现突出。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>所以，AR方式所带来的自回归性学习了预测 token 之间的依赖，这是 BERT 所没有的；而 BERT 的AE方式带来的对深层次双向信息的学习，却又是像ELMo还有GPT单向语言模型所没有的，不管是有没有替换 [MASK]。于是，自然就会想，如何将两者的优点统一起来？这时就到了XLNet登场的时间。</p>
<h2 id="2-Permutation-Language-Model"><a href="#2-Permutation-Language-Model" class="headerlink" title="2. Permutation Language Model"></a>2. Permutation Language Model</h2><img src="/2021/10/28/bert%E5%92%8Cxlnet/4.awebp" class="" title="Permutation Language Model">

<p>具体实现方式是，通过随机取一句话的一种排列，然后将末尾一定量的词给遮掩（和 BERT 里的直接替换 [MASK] 有些不同）掉，最后用 AR 的方式来按照这种排列依次预测被遮掩掉的词。</p>
<img src="/2021/10/28/bert%E5%92%8Cxlnet/5.awebp" class="" title="Permutation Language Model">

<h2 id="3-Transformer-XL"><a href="#3-Transformer-XL" class="headerlink" title="3. Transformer-XL"></a>3. Transformer-XL</h2><h2 id="4-Relative-Positional-Encoding"><a href="#4-Relative-Positional-Encoding" class="headerlink" title="4. Relative Positional Encoding"></a>4. Relative Positional Encoding</h2><h2 id="简单知识点"><a href="#简单知识点" class="headerlink" title="简单知识点"></a>简单知识点</h2><h3 id="1-bert-mask之间相互独立"><a href="#1-bert-mask之间相互独立" class="headerlink" title="1. bert mask之间相互独立"></a>1. bert mask之间相互独立</h3><p>BERT进行了独立假设，比如句子[New, York, is, a, city]， 假定MASK掉New York，输入为[MASK, MASK, is, a, city], Bert根据is a city 预测New; 根据is a city预测York. 也就是预测New和预测York是独立的，不相关的。</p>
<img src="/2021/10/28/bert%E5%92%8Cxlnet/1.jpg" class="" title="相互独立">
<p>作者提出的Generalized Autoregressive LM在预测York依赖了New。</p>
<img src="/2021/10/28/bert%E5%92%8Cxlnet/2.jpg" class="" title="依赖new">

<p>总结：BERT: Masked Language Model, 使用了双边的context信息，但是忽略了masked token之间的依赖关系。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6953820168002732040">一文看懂XLNet</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">算法</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/10/28/bert%E5%92%8Cxlnet/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/5/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" href="/page/7/">Next &amp;raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2024 张宇
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">技术</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">小桥流水人家</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">MySQL</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">flutter</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">machine learning</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">SQLAlchemy</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">python</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">CI</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">git</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">go</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">grpc</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">机器学习</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://github.com/geasyheart/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Github</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.google.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>Google</a>
            </li>
          
            <li class="search-li">
              <a href="https://stackoverflow.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>StackOverFlow</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">探索世界美好的存在。</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>